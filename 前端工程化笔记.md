# 前端工程化笔记



## 通用概念

#### Tree Shaking

##### 概念

Tree Shaking 是一种<font color=red>基于 ES Module 规范的 Dead Code Elimination 技术</font>，通过 <font color=red>**静态分析** 模块间的导入导出关系，精确识别并移除未被引用的代码，从而显著减小最终打包体积并提升应用性能</font>。<font color=lightSeaGreen>这一技术最初由 Rich Harris 在 Rollup 中创新性地实现</font>，随后 Webpack 在 2.0 版本开始支持，如今已成为现代前端工程中不可或缺的优化手段。Tree Shaking 的成功依赖于 ES Module 的静态结构特性，使构建工具能够在编译阶段确定代码的使用情况，这也是它区别于传统 CommonJS 模块优化的关键所在。

##### 为什么 Commonjs 不能实现 tree shaking

CommonJS 无法实现 Tree Shaking 的深层原因在于其动态特性与运行时行为：

CommonJS 模块系统允许高度动态的导入模式。开发者可以在条件语句中使用 `require()`，支持变量路径导入，甚至允许在任何作用域中导入模块。例如：

```js
if (process.env.NODE_ENV === "development") {
  require("./debug-tools");
}

const moduleId = getModuleId();
const module = require(`./modules/${moduleId}`);
```

同时，CommonJS 采用值拷贝的导出方式，导出的是完整模块对象。即使只使用一个属性，也必须导入整个模块对象，无法在编译时确定使用了哪些具体导出项。依赖解析发生在执行阶段，模块关系图只有在代码实际运行时才能完全确定。静态分析工具无法可靠地预测所有可能的模块加载路径，动态 `require` 调用的结果依赖于运行时环境和条件。

<font color=dodgerBlue>相比之下，`ES Modules` 的设计从根本上解决了这些问题：</font>

`ES Modules` 严格限制导入导出语句的位置和形式，所有 `import` / `export` 必须位于模块顶层。下面的代码在 ESM 中是非法的：

```js
if (condition) {
  import { foo } from "./module"; // 语法错误！
  export const bar = "bar"; // 语法错误！
}
```

这种限制使得模块依赖图在编译时完全确定。`ES Modules` 支持精确的导入导出关系，可以明确指定需要的导出项，构建工具能够创建精确的依赖关系图，确定哪些导出项实际被使用。

此外，`ES Modules` 的编译时可分析性也很关键。模块说明符必须是字符串字面量，编译器可以在不执行代码的情况下构建完整的模块依赖图，准确识别哪些导出项从未被任何模块引用。

因此，`ES Modules` 的这些特性为 Tree Shaking 提供了必要的静态分析基础，使构建工具能够准确识别并移除未使用的代码，从而大幅减小最终打包体积。

摘自：[Tree Shaking 是如何工作的？带你读懂 Webpack 的源码逻辑](https://mp.weixin.qq.com/s/EK6X0miodqfcSDehCgjnqw)



## Monorepo

##### 一些资料

[monorepo.tools](https://monorepo.tools)



##### Multirepo 的缺点

> 👀 Multirepo 也被称为 Polyrepo，不过根据 “poly” 的含义而言，也很好理解

- 跨仓库开发：多仓维护成本高
- 开发调试：npm 包（修改 -> 发布 -> 安装 成本高），调试麻烦 ( npm link )，
- 版本管理：依赖版本同步升级管理麻烦
- 项目基建：脚手架升级，新老项目规范很难保证统一

##### Monorepo 项目目录结构

```
├── packages/
│   ├── module1/
│   │   ├── src/
│   │   ├── tests/
│   │   ├── package.json
│   │   └── ...
│   ├── module2/
│   │   ├── src/
│   │   ├── tests/
│   │   ├── package.json
│   │   └── ...
│   └── shared/
│       ├── src/
│       ├── tests/
│       ├── package.json
│       └── ...
├── libs/
│   ├── lib1/
│   │   ├── src/
│   │   ├── tests/
│   │   ├── package.json
│   │   └── ...
│   ├── lib2/
│   │   ├── src/
│   │   ├── tests/
│   │   ├── package.json
│   │   └── ...
│   └── ...
├── docs/
├── .gitignore
├── package.json
└── ...
```

> 💡 其中 lib 适用于发包的，即 utils lib

> 💡 关于 monorepo 的项目目录结构可以看下 [Github - babel](https://github.com/babel/babel) 的目录结构。
>
> > 随着前端工程的日益复杂，越来越多的项目开始使用 monorepo。之前对于多个项目的管理，我们一般都是使用多个 git 仓库，但 monorepo 的宗旨就是用一个 git 仓库来管理多个子项目，所有的子项目都存放在根目录的 packages 目录下，那么一个子项目就代表一个 package 。如果你之前没接触过 monorepo 的概念，建议仔细看看这篇文章 [What Is a Monorepo?](https://www.perforce.com/blog/vcs/what-monorepo) ，以及开源的 monorepo 管理工具 [lerna](https://github.com/lerna/lerna) ，项目目录结构可以参考一下 [babel](https://github.com/babel/babel) 仓库。
> >
> > 摘自：[关于现代包管理器的深度思考——为什么现在我更推荐 pnpm 而不是 npm/yarn?](https://juejin.cn/post/6932046455733485575)

##### Monorepo 项目间代码如何共享？

<font color=dodgerBlue>举个例子：</font>

假设 lib 的包名为 `@my-scope/lib` ，<font color=lightSeaGreen>无需发包至 npm</font> 。

<font color=red>在一级目录的 `package.json` 添加包名 `@my-scope/lib: "workspace:*"`</font> 。

在两个 projects 中的代码中引入：

```js
import { method } from '@my-scope/lib';
```

##### 使用 pnpm 的 Monorepo 实战

###### 设置子项目目录数组

创建 Monorepo 项目后，在 `package.json` 文件中添加一个 `workspaces` 字段，并设置为一个包含子项目目录的数组；比如：

```json
"workspaces": [
  "packages/*"
]
```

> 💡 这里开始以为作者搞错了，毕竟 vue3 文档中在 `pnpm-workspace.yaml` 中有如下定义：
>
> ```yaml
> packages:
>   - 'packages/*'
> ```
>
> 便以为作者搞错了。但看了下 [npm v9 - package.json # workspaces](https://docs.npmjs.com/cli/v9/configuring-npm/package-json#workspaces) 的内容，发现确实有这个设置。
>
> > ###### workspaces
> >
> > The optional `workspaces` field is <font color=lightSeaGreen>an array of file patterns</font> that <font color=red>describes locations within the local file system</font> that the install client should look up to find each [workspace](https://docs.npmjs.com/cli/v9/using-npm/workspaces) that needs to be symlinked to the top level `node_modules` folder.
> >
> > It can describe <font color=dodgerBlue>either</font> the direct paths of the folders to be used as workspaces <font color=dodgerBlue>or</font> it can define globs that will resolve to these same folders.
> >
> > In the following example, <font color=red>all folders located inside the folder `./packages` will be treated as workspaces</font> <font color=lightSeaGreen>**as long as they have valid `package.json` files inside them**</font>:
> >
> > ```json
> > {
> >     "name": "workspace-example",
> >     "workspaces": [
> >       "./packages/*"
> >     ]
> > }
> > ```
> >
> > See [`workspaces`](https://docs.npmjs.com/cli/v9/using-npm/workspaces) for more examples.
>
> 同时问了下 gpt ：“在 `package.json` 中设置 `workspaces` 和 在 `pnpm-workspace.yaml` 中设置 `packages` 是否存在区别？”
>
> <img src="https://s2.loli.net/2023/05/29/sU1pQTHG5qWSzDh.png" alt="image-20230529181659686" style="zoom:50%;" />

新建两个项目（比如说是 vue 项目），在每个子项目的目录下，都有一个独立 `package.json` 文件

在 Monorepo 项目的根目录下运行 `pnpm install` 命令，将会为所有工作空间自动安装依赖

###### 安装公共依赖包

使用 `-w` 选项

```sh
pnpm install react -w
pnpm install rollup -wD # 安装开发依赖
```

> 💡根据 [pnpm doc - `pnpm add <pkg>`](https://pnpm.io/zh/cli/add) 的说法，`-w` 是 `--ignore-workspace-root-check`
>
> > ##### `--ignore-workspace-root-check`
> >
> > 除非使用 `--ignore-workspace-root-check` 或 `-w` 来标记，否则在 root workspace 包添加依赖项时会失败。例如， `pnpm add debug -w`
>
> 💡 根据文档所说，依赖安装时默认是无法以 “Monorepo 全局” 层级安装的

###### 给某个子项目单独安装指定依赖

使用 `--filter` 选项，可见 [[#pnpm 过滤 `--filter`]]

```sh
pnpm add axios --filter @package1
```

###### 模块之间的相互依赖

```sh
pnpm install @package2 -r --filter @package1
```

在设置依赖版本的时候推荐用 `workspace:*` ，这样就可以保持依赖的版本是工作空间里最新版本，不需要每次手动更新依赖版本。

##### pnpm Monorepo 优缺点

###### 优点

- 天然支持 Monorepo（在根目录给所有空间安装依赖、在根目录单独给子包安装依赖）

###### 缺点

- 需要手动提升公共依赖

- 需要手动指定任务 ( dev, build ) 执行，任务不支持并行执行，影响构建速度

- 不支持自动版本控制，需要依赖第三方工具，官方推荐两个工具 [changesets](https://github.com/changesets/changesets)、[Rush](https://rushjs.io)

- 没有通用的脚手架模板

- 不支持缓存

- 不支持依赖分析

> 👀 这里后面还介绍了 Lerna 和 Turborepo 的使用方法和优缺点，由于介绍的有点混乱，且不体系；这里不做摘抄，有时间的话还是专门去了解一下这两个工具。

摘自：[初识Monorepo](https://juejin.cn/post/7237145375311839289)



## 微前端

// TODO

[理解微前端](https://mdnice.com/writing/4cf8361de47d43d887982a755445edd1) ：已经看完，感觉很不错，也涉及了和 component islands pattern 的比较

[mirco-frontends 官网](https://micro-frontends.org)

[martin fowler - Micro Frontends](https://martinfowler.com/articles/micro-frontends.html)



## npm 及 npm-like 通用概念



#### npm 命令

##### `npm add`

> 👀 `npm add` 命令是我在 [Vite Doc - 使用插件 # 添加一个插件](https://cn.vitejs.dev/guide/using-plugins.html#adding-a-plugin) 中的 `npm add -D @vitejs/plugin-legacy` 发现的

`npm add` 是 `npm install` 的别名。

另外，在 npm 8.x 中加入了新的特性： `npm isntall`、`npm instal` 同样是可以执行的，且效果和 `npm install` 一致（换句话说：以上命令是 `npm install` 的别名）。所以：`npm install` 一共有 `i, in, ins, inst, insta, instal, isnt, isnta, isntal, isntall` 这十个别名

摘自：[NPM这6个有趣实用的知识点，你知道几个？🤩](https://juejin.cn/post/7095903278084390948)



##### `npm home` & `npm repo`

`npm home PACKAGE_NAME`  可以用于打开 PACKAGE_NAME 对应的主页，比如 `npm home react` 将会打开 `https://react.dev`

`npm repo PACKAGE_NAME`  可以用于打开 PACKAGE_NAME 对应的仓库地址，比如 `npm repo react` 将会打开 [Github repo - react - packages - react](https://github.com/facebook/react/tree/HEAD/packages/react)

学习自：[N 个值得一看的前端代码片段](https://juejin.cn/post/7371312967781777418)



##### npm scripts 可执行命令查询顺序

npm scripts 查询对应的可执行命令是有查找顺序的。首先，会从 `node_modules/.bin/` 下查找；找不到，则会到全局 global 中寻找；再找不到，会去环境变量中寻找；还是找不到，则会报错。

学习自：[小满zs - react最新教程 - React基础篇(开发环境搭建)](https://www.bilibili.com/video/BV1mcpPeMETt&p=2)



#### `npm install` / `yarn install` 原理

主要分为两个部分。首先，执行 `npm install` / `yarn install` 后，包如何到达项目 `node_modules` 中。其次，`node_modules` 内部如何管理依赖。

<font color=dodgerBlue>执行命令后，首先</font>会 <font color=red>**构建依赖树**</font>，<font color=dodgerBlue>然后</font> <font color=lightSeaGreen>**针对每个节点下的包**</font>，<font color=dodgerBlue>会经历下面四个步骤</font>：

1. 将依赖包的版本区间<font color=red>解析为某个具体的版本号</font>
2. 下载对应版本依赖的 tar 包到本地离线镜像
3. 将依赖从离线镜像解压到本地缓存
4. 将依赖从缓存拷贝到当前目录的 `node_modules` 目录

<font color=lightSeaGreen>然后，对应的包就会到达项目的 `node_modules` 中</font>。

那么，这些依赖在 `node_modules` 内部是什么样的目录结构呢，换句话说，项目的依赖树是什么样的呢？

在 npm v1 、npm v2 中呈现出的是嵌套结构，比如下面这样：

```tree
node_modules
└─ foo
   ├─ index.js
   ├─ package.json
   └─ node_modules
      └─ bar
         ├─ index.js
         └─ package.json
```

<font color=lightSeaGreen>如果 bar 当中又有依赖，那么**又会继续嵌套下去**</font>。试想一下<font color=dodgerBlue>这样的设计存在什么问题</font>：

1. <font color=lightSeaGreen>依赖层级太深，会引发文件路径过长的问题</font>，尤其在 window 系统下。
2. 大量重复的包被安装，文件体积超级大。比如跟 foo 同级目录下有一个 baz，两者都依赖于同一个版本的lodash，那么 lodash 会分别在两者的 `node_modules` 中被安装，即：重复安装。
3. <font color=red>模块实例不能共享</font>。比如 React 有一些内部变量，在两个不同包引入的 React 不是同一个模块实例，因此无法共享内部变量，导致一些不可预知的 bug。

<font color=dodgerBlue>从 npm v3 开始，包括 yarn</font>，<font color=red>都着手来通过扁平化依赖的方式来解决这个问题</font>。相信大家都有这样的体验：明明就装个 `express`，为什么 `node_modules` 里面多了这么多东西？

<img src="https://s2.loli.net/2025/02/07/tkGVJvL28BKDbPR.webp" style="zoom:50%;" />

这就是 “扁平化” 依赖管理的结果。相比之前的 “嵌套结构”，现在的目录结构类似下面这样：

```tree
node_modules
├─ foo
|  ├─ index.js
|  └─ package.json
└─ bar
   ├─ index.js
   └─ package.json
```

所有的依赖都被拍平到 `node_modules` 目录下，不再有很深层次的嵌套关系。<font color=dodgerBlue>这样在安装新的包时</font>，<font color=red>根据 node require 机制，会不停向上级的 `node_modules` 中去找</font>，<font color=lightSeaGreen>如果找到相同版本的包就不会重新安装</font>，解决了大量包重复安装的问题，而且依赖层级也不会太深。

<font color=dodgerBlue>之前的问题是解决了</font>，但仔细想想<font color=dodgerBlue>**这种 “扁平化” 的处理方式，真的就是无懈可击吗**</font>？<font color=red>并不是</font>。它<font color=dodgerBlue>照样存在诸多问题，梳理一下</font>：

1. 依赖结构的**不确定性**

2. <font color=red>扁平化算法本身的**复杂性**很高，耗时较长</font>

3. 项目中仍然可以**非法访问**没有声明过依赖的包

   > 👀 即：未解决 “幽灵依赖” 的问题

后面两个都好理解，<font color=dodgerBlue>**第一点中的 “不确定性” 是什么意思**？这里来详细解释一下</font>：

假如现在项目依赖两个包 foo 和 bar，这两个包的依赖又是这样的：

<img src="https://s2.loli.net/2025/02/07/8527iQMOw1kmTtv.webp" style="zoom:50%;" />

那么 `npm install` / `yarn install` 的时候，通过扁平化处理之后，究竟是这样

<img src="https://s2.loli.net/2025/02/07/VIXuc45CMFYWgRZ.webp" style="zoom:45%;" />

还是这样？

<img src="https://s2.loli.net/2025/02/07/5RaG8kP1OsdSDCf.webp" style="zoom:40%;" />

<font color=red>答案是 **都有可能**</font>。这取决于 foo 和 bar 在 `package.json` 中的位置，如果 foo 声明在前面，那么就是前面的结构，否则是后面的结构。

<font color=dodgerBlue>**这就是为什么会产生 “依赖结构的不确定” 问题，这也是 “lock 文件” 诞生的原因**</font>，无论是 `package-lock.json`（npm 5.x 才出现）还是 `yarn.lock` ，<font color=fuchsia>**都是为了保证 install 之后都产生确定的 `node_modules` 结构**</font>。

> 👀 上面的 “解决‘依赖结构的不确定性’的问题，保证 install 之后都产生确定的 `node_modules` 结构” 这一观点，之前并没有听过，值得注意

尽管如此，npm / yarn 本身还是存在 “扁平化算法复杂” 和 “package 非法访问”（幽灵依赖）的问题，影响性能和安全。

学习自：[关于现代包管理器的深度思考——为什么现在我更推荐 pnpm 而不是 npm/yarn?](https://juejin.cn/post/6932046455733485575)



#### package.json 与配置

##### `peerDependencies`

In some cases, you want to express the compatibility of your package with a host tool or library, while not necessarily doing a `require` of this host. This is usually referred to as a *plugin*. Notably, your module may be exposing a specific interface, expected and specified by the host documentation.

For example:

```json
{
  "name": "@npm/tea-latte",
  "version": "1.3.5",
  "peerDependencies": {
    "@npm/tea": "2.x"
  }
}
```

<font color=red>This ensures your package `@npm/tea-latte` can be installed *along* with **the second major version** of the host package `@npm/tea` only</font>. `npm install tea-latte` could possibly yield the following dependency graph:

```
├── @npm/tea-latte@1.3.5
└── @npm/tea@2.2.0
```

<font color=dodgerBlue>In npm versions 3 through 6</font>, `peerDependencies` were not automatically installed, and <font color=lightSeaGreen>would **raise a warning** if an invalid version of the peer dependency was found in the tree</font>. <font color=dodgerBlue>As of npm v7</font>, <font color=red>peerDependencies *are* installed by default</font>.

<font color=dodgerBlue>Trying to install another plugin with a conflicting requirement</font> may cause an error if the tree cannot be resolved correctly. For this reason, make sure your plugin requirement is as broad as possible, and not to lock it down to specific patch versions.

Assuming the host complies with [semver](https://semver.org/) , only changes in the host package's major version will break your plugin. Thus, if you've worked with every 1.x version of the host package, use `"^1.0"` or `"1.x"` to express this. If you depend on features introduced in 1.5.2, use `"^1.5.2"` .



##### `overrides`

If you need to <font color=dodgerBlue>**make specific changes** to **dependencies of your dependencies**</font>, for example replacing the version of a dependency with a known security issue, replacing an existing dependency with a fork, or <font color=red>making sure that the same version of a package is used everywhere</font>, then <font color=lightSeaGreen>you may add an override</font>.

Overrides provide a way to replace a package in your dependency tree with another version, or another package entirely. These changes can be scoped as specific or as vague <font color=red>**as desired**</font>.

> 👀 说明了：覆盖范围可大可小，随着配置而改变

Overrides are <font color=red>only considered in the root `package.json` file for a project</font>. Overrides in installed dependencies (including [workspaces](https://docs.npmjs.com/cli/v11/using-npm/workspaces)) are not considered in dependency tree resolution. <font color=dodgerBlue>Published packages</font> may dictate their resolutions by pinning dependencies or using an [`npm-shrinkwrap.json`](https://docs.npmjs.com/cli/v11/configuring-npm/npm-shrinkwrap-json) file.

To make sure the package `@npm/foo` is always installed as version `1.0.0` no matter what version your dependencies rely on:

```json
{
  "overrides": {
    "@npm/foo": "1.0.0"
  }
}
```

<font color=dodgerBlue>The above is a short hand notation</font>, the full object form can be used to allow overriding a package itself as well as a child of the package. This will cause `@npm/foo` to always be `1.0.0` <font color=red>while also making `@npm/bar` at any depth beyond `@npm/foo` also `1.0.0`</font> :

```json
{
  "overrides": {
    "@npm/foo": {
      ".": "1.0.0",
      "@npm/bar": "1.0.0"
    }
  }
}
```

To <font color=red>**only** override `@npm/foo` to be `1.0.0` when it's a child (or grandchild, or great grandchild, etc) of the package `@npm/bar`</font>:

```json
{
  "overrides": {
    "@npm/bar": {
      "@npm/foo": "1.0.0"
    }
  }
}
```

<font color=dodgerBlue>**Keys can be nested to any arbitrary length**</font>. To override `@npm/foo` only when it's a child of `@npm/bar` and only when `@npm/bar` is a child of `@npm/baz`:

```json
{
  "overrides": {
    "@npm/baz": {
      "@npm/bar": {
        "@npm/foo": "1.0.0"
      }
    }
  }
}
```

<font color=red>The key of an override can also include a version, or range of versions</font>. To override `@npm/foo` to `1.0.0`, but only when it's a child of `@npm/bar@2.0.0`:

```json
{
  "overrides": {
    "@npm/bar@2.0.0": {
      "@npm/foo": "1.0.0"
    }
  }
}
```

<font color=red>You may not set an override for a **package that you directly depend on**</font> unless both the dependency and the override itself share the exact same spec. <font color=dodgerBlue>To make this limitation easier to deal with</font>, overrides may also be defined as a reference to a spec for a direct dependency **by prefixing the name of the package you wish the version to match with a `$`** .

> 🌏 除非依赖项和覆盖本身具有完全相同的规范，否则您不能为直接依赖的软件包设置覆盖。为了更容易处理这种限制，还可以通过在期望的版本匹配的软件包名称前加上 `$` 来将覆盖定义为对直接依赖项规范的引用

```json
{
  "dependencies": {
    "@npm/foo": "^1.0.0"
  },
  "overrides": {
    // BAD, will throw an EOVERRIDE error
    // "foo": "^2.0.0"
    // GOOD, specs match so override is allowed
    // "foo": "^1.0.0"
    // BEST, the override is defined as a reference to the dependency
    "@npm/foo": "$foo",
    // the referenced package does not need to match the overridden one
    "@npm/bar": "$foo"
  }
}
```



##### 指定项目运行的系统环境

> 👀 可以通过 `engines` 、`os` 、`cpu` 选项，指定项目运行的系统环境

###### `engines`

You can specify the version of node that your stuff works on:

```json
{
  "engines": {
    "node": ">=0.10.3 <15"
  }
}
```

And, like with dependencies, if you don't specify the version (or if you specify "*" as the version), then any version of node will do.

You can also <font color=red>use the "engines" field to **specify which versions of npm** are capable of properly installing your program</font>. For example:

```json
{
  "engines": {
    "npm": "~1.0.20"
  }
}
```

Unless the user has set the [`engine-strict` config](https://docs.npmjs.com/cli/v11/using-npm/config#engine-strict) flag, <font color=lightSeaGreen>this field is advisory only and will **only produce warnings** when your package is installed as a dependency</font>.

###### `os`

You can specify which operating systems your module will run on:

```json
{
  "os": ["darwin", "linux"]
}
```

You can also <font color=dodgerBlue>block instead of allowing operating systems</font>, just prepend the <font color=red>blocked os with a '!'</font>:

```json
{
  "os": ["!win32"]
}
```

<font color=red>The host operating system is determined by `process.platform`</font>

It is allowed to both block and allow an item, although there isn't any good reason to do this.

###### `cpu`

If your code only runs on certain cpu architectures, you can specify which ones.

```json
{
  "cpu": ["x64", "ia32"]
}
```

Like the `os` option, you can also block architectures:

```json
{
  "cpu": ["!arm", "!mips"]
}
```

The host architecture is determined by `process.arch`



#### package-lock.json

##### 作用

`package-lock.json` 除了 “锁定依赖的版本号” 功能之外，也具有缓存的作用，通过 “名字 + `version` + `resolved` ” 这三者的混合形成一个 hash 值，接下来会和 `integrity` 对比一下，如果能在目录里面能对上，则直接把 node_modules 包拿出来，无需下载

学习自：[小满zs - react最新教程 - React基础篇(开发环境搭建)](https://www.bilibili.com/video/BV1mcpPeMETt&p=2)

> 👀 补充
>
> 上面所说 “锁定依赖的版本号” 的功能，感觉并不全面，这里做下补充。不仅仅是锁定版本号，也有解决 “依赖结构的不确定性” 的问题、保证 `node_modules` 文件结构一致性的功能，如上面 [[#`npm install` / `yarn install` 原理]] 中所说：
> > <font color=dodgerBlue>**这就是为什么会产生 “依赖结构的不确定” 问题，这也是 “lock 文件” 诞生的原因**</font>，无论是 `package-lock.json`（npm 5.x 才出现）还是 `yarn.lock` ，<font color=fuchsia>**都是为了保证 install 之后都产生确定的 `node_modules` 结构**</font>。



#### npx

##### npm vs npx

###### npm

用于安装和管理 Node.js 包，通过 `package.json` 文件管理项目依赖。

通过 `npm install {your-package}` 命令安装包，并检查 `package.json` 文件中的依赖项。

###### npx

用于<font color=red>直接执行 npm 包</font>，<font color=red>**无需全局安装**</font>，<font color=red>特别适用于一次性使用的包</font>。

通过 `npx {package-name}` 命令直接执行包，如果包未安装，npx 会自动下载并执行。例如，`npx create-react-app my-app` 可以直接创建一个新的 React 应用。

###### 影响

这种对 npm 和 npx 的清晰区分有助于开发者更有效地选择和使用工具。<font color=red>特别是对于那些需要频繁测试和部署新包的开发者，npx 提供了一种更加便捷和高效的方式</font>。此外，这也促进了 Node.js 生态系统的健康发展，使得包的管理和执行更加规范和高效。

###### 结论

总的来说，npm 和 npx 在 Node.js 开发中各有其独特的角色和优势。npm 主要用于包的管理和安装，而 npx 则提供了一种更加灵活和便捷的包执行方式。

摘自：[【早阅】npm vs npx - 基本区别是什么？](https://mp.weixin.qq.com/s/m8mnxTDNVbBV8VOSawHJ2Q) ，原文 [npm vs npx — What are the Basic Difference?](https://dev.to/shariqahmed525/npm-vs-npx-what-are-the-basic-difference-57dk)



#### `.npmrc` 相关

##### `.npmrc` 的优势

相较使用 `npm config set registry registryUrl` 的方式，修改 npm 的源的配置，同时也修改了  `~/.npmrc` 中的配置。而使用 `.npmrc`（不仅仅是 `~/.npmrc` ，详见 [[#` .npmrc` 相关文档摘抄]] ） 是更好的选择：因为它提供了更细粒度的配置，比如 每个项目中local 的 `.npmrc` 。

会有这样一个问题：如果希望部分依赖下载自默认的某个源，而另一部分的依赖下载自另一个源，使用 `npm config set registry registryUrl` 的方式显然无法解决；这时可以在 `~/.npmrc` 中配置。

```ini
registry = https://registry.npm.taobao.org/
@juejin:registry = https://siyouyuan.org/
```

以上两行代码分别做了如下两件事：

1. `@juejin` 命名空间的项目，直接在私有源请求包
2. 其他包则从 `taobao` 源发起请求。

学习自：[NPM这6个有趣实用的知识点，你知道几个？🤩](https://juejin.cn/post/7095903278084390948)

##### ` .npmrc` 相关文档摘抄

###### Files

The four relevant files are

- per-project config file ( `/path/to/my/project/.npmrc` ) 👀 local config

  When working locally in a project, a `.npmrc` file <font color=LightSeaGreen>in the root of the project</font> (ie, a sibling of `node_modules` and `package.json`) will set config values specific to this project.

  Note that <font color=LightSeaGreen>this only applies to the root of the project</font> that you're running npm in（🌏 运行）. It has no effect when your module is published. For example, you can't publish a module that forces itself to install globally, or in a different location.

  Additionally, this file is not read in global mode, such as when running `npm install -g`.

- per-user config file ( `~/.npmrc` ) 👀 user config

  `$HOME/.npmrc` (or the `userconfig` param, if set in the environment or on the command line)

- global config file ( `$PREFIX/etc/npmrc` ) 👀 global config

  `$PREFIX/etc/npmrc` (or the `globalconfig` param, if set above): This file is an ini-file formatted list of `key = value` parameters. Environment variables can be replaced as above.

- npm built-in config file ( `/path/to/npm/npmrc` )

  This is an <font color=red>unchangeable "builtin" configuration file</font> that <font color=red>npm keeps consistent across updates</font>. Set fields in here using the `./configure` script that comes with npm. This is primarily for distribution maintainers to override default configs in a standard and consistent manner.

> 👀 感觉可以和 Git 的 local、global、system 三种作用域做一下类比

All npm config files are an <font color=red>**ini-formatted** list of `key = value` parameters</font>. Environment variables can be replaced using `${VARIABLE_NAME}` . For example:

```ini
prefix = ${HOME}/.npm-packages
```

Each of these files is loaded, and <font color=red>config options are resolved in priority order</font>（🌏 按优先顺序排列）. For example, a setting in the <font color=LightSeaGreen>userconfig file would override the setting in the globalconfig file</font>.

<font color=dodgerBlue>Array values are specified by adding "[]" after the key name</font>. For example:

```ini
key[] = "first value"
key[] = "second value"
```

###### Comments

Lines in `.npmrc` files are interpreted as comments when they begin with a `;` or `#` character. `.npmrc` files are parsed by [npm/ini](https://github.com/npm/ini), which specifies this comment syntax. For example:

```ini
# last modified: 01 Jan 2016
; Set a new registry for a scoped package
@myscope:registry=https://mycustomregistry.example.org
```

###### Auth related configuration

The settings `_auth`, `_authToken`, `username` and `_password` must all be scoped（🌏 限定范围的） to a specific registry. <font color=red>This ensures that `npm` will never send credentials to the wrong host</font>.

<font color=dodgerBlue>The full list is:</font>

- `_auth` (base64 authentication string)
- `_authToken` (authentication token)
- `username`
- `_password`
- `email`
- `certfile` (path to certificate file)
- `keyfile` (path to key file)

<font color=red>In order to scope these values, they must be prefixed by a URI fragment</font>. If the credential is meant for any request to a registry on a single host, the scope may look like `//registry.npmjs.org/:`. If it must be scoped to a specific path on the host that path may also be provided, such as `//my-custom-registry.org/unique/path:`.

```ini
; bad config
_authToken=MYTOKEN

; good config
@myorg:registry=https://somewhere-else.com/myorg
@another:registry=https://somewhere-else.com/another
//registry.npmjs.org/:_authToken=MYTOKEN
; would apply to both @myorg and @another
; //somewhere-else.com/:_authToken=MYTOKEN
; would apply only to @myorg
//somewhere-else.com/myorg/:_authToken=MYTOKEN1
; would apply only to @another
//somewhere-else.com/another/:_authToken=MYTOKEN2
```

摘自：[npm Docs - .npmrc](https://docs.npmjs.com/cli/v9/configuring-npm/npmrc)



#### npmignore

##### npm 文档摘抄

**Use a `.npmignore` file to keep stuff out of your package**. <font color=dodgerBlue>If there's no `.npmignore` file, but there *is* a `.gitignore` file</font>, then <font color=red>npm will ignore the stuff matched by the `.gitignore` file</font>. <font color=dodgerBlue>If you *want* to include something that is excluded by your `.gitignore` file</font>, you can <font color=lightSeaGreen>create an empty `.npmignore` file to override it</font>. Like `git`, `npm` looks for `.npmignore` and `.gitignore` files in all subdirectories of your package, not only the root directory.

`.npmignore` files follow the [same pattern rules](https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository#_ignoring) as `.gitignore` files:

- Blank lines or lines starting with `#` are ignored.
- Standard glob patterns work.
- You can end patterns with a forward slash `/` to specify a directory.
- You can negate a pattern by starting it with an exclamation point `!`.

<font color=dodgerBlue>By default</font>, <font color=dodgerBlue>**the following paths and files are ignored**</font>, so there's no need to add them to `.npmignore` explicitly:

- `.*.swp`
- `._*`
- `.DS_Store`
- `.git`
- `.gitignore`
- `.hg`
- `.npmignore`
- `.npmrc`
- `.lock-wscript`
- `.svn`
- `.wafpickle-*`
- `config.gypi`
- `CVS`
- `npm-debug.log`

<font color=dodgerBlue>Additionally</font>, <font color=lightSeaGreen>everything in `node_modules` is ignored</font>, except for bundled dependencies. npm automatically handles this for you, so don't bother adding `node_modules` to `.npmignore`.

<font color=dodgerBlue>The following paths and files are **never ignored**</font>, so adding them to `.npmignore` is pointless:

- `package.json`
- `README` (and its variants)
- `CHANGELOG` (and its variants)
- `LICENSE` / `LICENCE`

If, given the structure of your project, you find `.npmignore` to be a maintenance headache, you might instead try populating the `files` property of `package.json`, which is an array of file or directory names that should be included in your package. Sometimes manually picking which items to allow is easier to manage than building a block list.

###### Testing whether your .npmignore or files config works

If you want to double check that your package will include only the files you intend it to when published, you can run the `npm pack` command locally which will generate a tarball in the working directory, the same way it does for publishing.

摘自：[npm Docs - cli - using npm - developers](https://docs.npmjs.com/cli/using-npm/developers)



##### 修改 node_modules 依赖代码

想要修改 node_modules 中依赖部分的代码（比如说：存在 bug），可以使用 [patch-package](https://github.com/ds300/patch-package) ，这个可以说是当前的 最佳实践。

> **About**
>
> Fix broken node modules instantly 🏃🏽‍♀️💨

另外，这个功能被 pnpm 内置了 [`pnpm patch <pkg>`](https://pnpm.io/zh/cli/patch)




#### workspaces 特性

##### 背景

在阅读 [What？你还不明白npm, yarn, pnpm之间的区别？！](https://juejin.cn/post/7433427781928386571) 时，发现这样一句话：

> npm v7+ ，改进了扁平化管理，引入peer dependencies 处理
>
> - 自动安装 peer dependencies
> - 更严格的版本锁定
> - 改进了依赖解析算法
> - workspaces 支持

前几个还能理解，但是 “ workspaces 支持” 有点理解不了；问了下 GPT，得到了如下解释：

> 👀 问题中的 “workspaces” 少打了 “s”，不过，问题还是被 AI 正确理解了

<img src="https://s2.loli.net/2024/12/10/lARLWYGNzmTujyC.png" alt="image-20241210225425934" style="zoom:50%;" />

其中，也就大概介绍了 monorepo 的一些特性，个人感觉： “workspaces” 特性是实现 monorepo 的一种手段。

另外，值得注意的是第二点，是之前没注意的；要么是被我忽略，要么可能是过于基础、之前看的文章忽略了。

### corepack

##### 简要介绍

As per [Node.js](https://nodejs.org/api/corepack.html) documentation, the corepack <font color=red>identifies the package manager</font> and <font color=red>installs in the background if needed without any user interaction</font>.

摘自：[How to Configure a React App with TypeScript, TailwindCSS, Yarn and Storybook](https://blog.bitsrc.io/how-to-configure-a-react-app-with-typescript-tailwindcss-yarn-and-storybook-a271df5d9884)

##### What's Corepack

Corepack <font color=red>makes sure you are using the correct version for package manager</font> when you run corresponding commands. <font color=red>Projects might have `packageManager` field in their `package.json`</font> .

Under projects with configuration as shown on the right（ 👀 现在是 below 了 ）, <font color=red>corepack will install `v7.1.5` of `pnpm` (if you don't have it already)</font> and use it to run your commands. <font color=fuchsia>This makes sure everyone working on this project have the same behavior for the dependencies and the lockfile</font>.

```json
// package.json
{
  "packageManager": "pnpm@7.1.5"
}
```

摘自：[GitHub - antfu/contribute](https://github.com/antfu/contribute)

#### Node Doc Intro

> 💡 Added in: v16.9.0, v14.19.0

##### 简介

*[Corepack](https://github.com/nodejs/corepack)* is an <font color=red>*experimental tool*</font> to <font color=red>help with **managing versions of your package managers**</font>. It <font color=fuchsia>exposes **binary proxies**</font>（👀 本质上是 包管理工具的 二进制**代理** ）<font color=fuchsia>for each supported package manager</font>（ 👀 目前是 pnpm 和 yarn ） that, <font color=dodgerBlue>when called</font>, <font color=red>will identify whatever package manager is configured for the current project</font>, download it if needed, and finally run it.

Despite <font color=red>Corepack **being distributed with default installs of Node.js**</font>, the package managers managed by Corepack are not part of the Node.js distribution and:

- <font color=dodgerBlue>Upon first use</font>, <font color=red>Corepack downloads the latest version from the network</font>.
- Any required updates (related to security vulnerabilities or otherwise) are out of scope of the Node.js project. If necessary end users must figure out how to update on their own.

<font color=dodgerBlue>This feature simplifies two core workflows:</font>

- <font color=LightSeaGreen>It eases new contributor onboarding</font>（加入）, since they won't have to follow system-specific installation processes anymore just to have the package manager you want them to.
- It allows you to <font color=LightSeaGreen>ensure that everyone in your team will **use exactly the package manager version** you intend them to</font>, without them having to manually synchronize it each time you need to make an update.

##### Workflows

###### Enabling the feature

<font color=dodgerBlue>Due to its experimental status</font>, Corepack currently needs to be explicitly enabled to have any effect. To do that, <font color=red>run `corepack enable`</font> , which <font color=red>will set up the symlinks in your environment next to the `node` binary</font> (and overwrite the existing symlinks if necessary).

From this point forward, any call to the *supported binaries*（👀 即 supported package manager ） will work without further setup. Should you experience a problem, <font color=red>run `corepack disable` to remove the proxies from your system</font> (and consider opening an issue on the [Corepack repository](https://github.com/nodejs/corepack) to let us know).

###### Configuring a package

The <font color=red>Corepack proxies will **find the closest `package.json` file in your current directory hierarchy**</font> to <font color=fuchsia>extract its `"packageManager"` property</font>.

If the value corresponds to a *supported package manager*, Corepack will make sure that all calls to the relevant binaries are run against the requested version, downloading it on demand if needed, and aborting if it cannot be successfully retrieved.

###### Upgrading the global versions

When running outside of an existing project (for example when running `yarn init` ) , <font color=red>Corepack will **by default** use predefined versions roughly corresponding to the latest stable releases from each tool</font>. <font color=fuchsia>Those versions can be overridden by running the `corepack prepare` command</font> along with the package manager version you wish to set:

```bash
corepack prepare yarn@x.y.z --activate
```

Alternately, a tag or range may be used:

```bash
corepack prepare pnpm@latest --activate
corepack prepare yarn@stable --activate
```

摘自：[Node doc - Corepack](https://nodejs.org/api/corepack.html)

## pnpm



##### Mac homebrew pnpm 更新问题

使用 Mac 上的 homebrew 更新 pnpm ，目前已经遇到多次，虽然 `brew upgrade pnpm` 已经将 pnpm 安装到了最新版（ brew 提示 pnpm 已经安装了最新的版本），但是 `pnpm -v` 显示还是停留在上一个大版本中。

###### 解决方法

```sh
brew link --overwrite pnpm
```

同时，需要注意的是：如果在 `package.json` 中指定了 `packageManager` ，比如 `"packageManager": "pnpm@8.15.0",` ，那么 pnpm 的版本也会随配置改变。



#### pnpm 原理与优势

###### 思维导图

<img src="https://s2.loli.net/2025/02/07/m6cNMDky47CtXro.webp" style="zoom:45%;" />

###### 优势总结

作为杀手锏的两个优势：

- 包安装速度极快
- 磁盘空间利用非常高效

##### 特点

###### 高效利用磁盘空间

<font color=red>**pnpm 内部使用 “基于内容寻址” 的文件系统来存储磁盘上所有的文件**</font>，<font color=dodgerBlue>这个文件系统出色的地方在于</font>：

- **不会重复安装同一个包**。<font color=dodgerBlue>用 npm / yarn 的时候，如果 100 个项目都依赖 lodash</font> ，那么 <font color=lightSeaGreen>lodash 很可能就被安装了 100 次，磁盘中就有 100 个地方写入了这部分代码</font>。但在<font color=red>使用 pnpm 只会安装一次，磁盘中只有一个地方写入，后面再次使用都会直接使用 **hardlink（硬链接）**</font>。
- <font color=dodgerBlue>即使**一个包的不同版本**</font>，<font color=fuchsia>pnpm 也会极大程度地复用之前版本的代码</font>。<font color=dodgerBlue>举个例子</font>，比如 lodash 有 100 个文件，<font color=dodgerBlue>更新版本之后多了一个文件</font>，那么磁盘当中并不会重新写入 101 个文件，而是保留原来的 100 个文件的 `hardlink` ，<font color=red>**仅仅写入那一个新增的文件**</font>。

###### 支持 monorepo

随着前端工程的日益复杂，越来越多的项目开始使用 monorepo 。之前对于多个项目的管理，我们一般都是使用多个 git 仓库，但 <font color=dodgerBlue>monorepo 的宗旨</font>就是<font color=lightSeaGreen>用一个 git 仓库来管理多个子项目</font>，<font color=lightSeaGreen>所有的子项目都存放在根目录的`packages` 目录下，一个子项目就代表一个 `package`</font> 。

pnpm 与 npm / yarn 另外一个很大的不同就是支持 monorepo，体现在各个子命令的功能上，比如：在根目录下 `pnpm add A -r` ，那么所有 package 都会被添加 A 这个依赖，也支持 `--filter` 选项来对 package 进行过滤。

###### 安全性高

> 👀 可以理解为：解决了 “幽灵依赖” 的问题

之前在使用 npm / yarn 的时候，由于 `node_module` 的扁平结构，如果 A 依赖 B， B 依赖 C，那么 A 当中是可以直接使用 C 的，但问题是 A 当中并没有声明 C 这个依赖。因此会出现这种非法访问的情况。但 pnpm 脑洞特别大，自创了一套依赖管理方式，很好地解决了这个问题，保证了安全性；规避非法访问依赖的风险。

##### `npm install` / `yarn install` 原理

> 👀 由于与 pnpm 不直接相关，只是用来引出存在哪些问题，并表明 pnpm 解决了这些问题；所以相关内容放在 [[### npm 及 npm-like 通用概念#`npm install` / `yarn install` 原理]]

##### pnpm 依赖管理

> 👀 相关内容在 [[#node_modules 目录结构]] 中已经有所介绍，相差不大，这里不再赘述；不过还是可以看下，互为补充。 
>
> 另外，文章在这里第一次提到了 <font color=red>“依赖提升”</font> 这个概念。这也和下面 [[#再谈安全]] 中解决的问题相关

##### 再谈安全

pnpm 这种依赖管理的方式也很巧妙地规避了 “非法访问依赖” 的问题，只要一个包未在 `package.json` 中声明依赖，那么在项目中是无法访问和使用的。

但在 npm / yarn 中是做不到的，那你可能会问了，如果 A 依赖 B， B 依赖 C，那么 A 就算没有声明 C 的依赖，由于有依赖提升的存在，C 被装到了 A 的 `node_modules` 里面，那我在 A 里面用 C，跑起来没有问题呀，我上线了之后，也能正常运行啊。不是挺安全的吗？<font color=dodgerBlue>**还真不是**</font>。

<font color=dodgerBlue>第一</font>，<font color=red>要知道 B 的版本是可能随时变化的</font>，假如之前依赖的是`C@1.0.1`，现在发了新版，新版本的 B 依赖 `C@2.0.1`，那么在项目 A 当中 `npm install` / `yarn install` 后，装上的是 2.0.1 版本的 C，而 <font color=lightSeaGreen>A 当中用的还是 C 当中旧版的 API，可能就直接报错了</font>。

<font color=dodgerBlue>第二</font>，<font color=red>如果 B 更新之后，可能不需要 C 了</font>，那么安装依赖的时候，C 都不会装到 `node_modules` 里面，A 当中引用 C 的代码直接报错。

<font color=dodgerBlue>还有一种情况</font>，<font color=lightSeaGreen>**在 monorepo 项目中**</font>，<font color=lightSeaGreen>如果 A 依赖 X，B 依赖 X，还有一个 C，它不依赖 X，但它代码里面用到了 X</font>。<font color=red>**由于依赖提升的存在**</font>，npm / yarn 会把 X 放到根目录的 `node_modules` 中，这样 C 在本地是能够跑起来的，因为<font color=red>根据 node 的包加载机制，它能够加载到 monorepo 项目根目录下的 `node_modules` 中的 X</font> 。但试想一下，<font color=lightSeaGreen>**一旦 C 单独发包出去**，用户单独安装 C，那么就找不到 X 了</font>，执行到引用 X 的代码时就直接报错了。

这些，都是依赖提升潜在的 bug。如果是自己的业务代码还好，试想一下如果是给很多开发者用的工具包，那危害就非常严重了。

摘自：[关于现代包管理器的深度思考——为什么现在我更推荐 pnpm 而不是 npm/yarn?](https://juejin.cn/post/6932046455733485575)



#### node_modules 目录结构

##### pnpm store 全局缓存存储地址

根据 [stack overflow - How to get pnpm store directory ](https://stackoverflow.com/a/71733442/13496313) 回答中的说法，可以通过 `pnpm store path` 以查看 pnpm store 的位置。在 Mac 中，是 `$HOME/Library/pnpm/store` 。另外，pnpm 文档中也有说明 [pnpm doc - Configuration - Settings (.npmrc) # store-dir](https://pnpm.io/npmrc#store-dir)

##### store 目录结构

存储形式是：内容寻址存储。这和 git 的 `.git` 中的 `objects` 文件夹的存储形式应该是一样的。

```
pnpm/store/
└── v3/
    └── files/
        ├── 00/                              # 前两位哈希值作为目录名
        │   └── deadbeef...                  # 包内容的哈希值
        └── ff/
            └── cafebabe...                  # 另一个包的哈希值
```

##### 依赖结构

```
node_modules/
├── .pnpm/
│   ├── react@17.0.2/
│   │   └── node_modules/
│   │       ├── react/                       # 实际文件(硬链接到 store)
│   │       └── loose-envify/                # react 的依赖
│   └── lodash@4.17.21/
│       └── node_modules/
│           └── lodash/                      # 实际文件(硬链接到 store)
├── react -> .pnpm/react@17.0.2/node_modules/react                 # 符号链接
└── lodash -> .pnpm/lodash@4.17.21/node_modules/lodash             # 符号链接
```

##### 目录说明

- **`.pnpm` 文件夹** ：<font color=red>存放项目的所有依赖包</font>，<font color=red>以 `包名@版本号` 命名</font>，并在其 `node_modules` 文件夹中包含该包的实际文件和依赖项。
- **硬链接** ：<font color=red>`.pnpm` 中的实际文件并不是直接复制到每个项目中</font>，而是<font color=fuchsia>通过**硬链接**指向 `pnpm` 的全局缓存存储目录</font> ( `pnpm store` )。这样，不同项目间的相同版本依赖不需要重复下载。
- **符号链接** ：`pnpm` 会在项目的 `node_modules` 根目录创建符号链接，将每个包链接到 `.pnpm` 中实际的包路径。例如：
  - `node_modules/react` 是一个符号链接，指向 `.pnpm/react@17.0.2/node_modules/react`
  - `node_modules/lodash` 符号链接指向 `.pnpm/lodash@4.17.21/node_modules/lodash`

> ⚠️ 这里值得强调的是：硬链接和符号链接在使用地方的区别。
>
> - `.pnpm` 文件夹中的内容通过 **硬链接** 的方式指向 pnpm store 中对应的内容
> - `node_modules` 根目录下的包文件通过 **符号链接** 的方式指向 `.pnpm` 文件夹中的内容

##### 工作原理

1. **包安装**：`pnpm` 会将依赖包下载到全局缓存 ( `pnpm store` ) 中，并将实际文件硬链接到 `.pnpm` 文件夹中的特定版本目录下。
2. **创建符号链接 **：在项目的 `node_modules` 文件夹内创建符号链接，将包名称指向 `.pnpm` 中的对应路径。
3. **引用** ：项目中的 `require('react')` 会自动找到 `node_modules/react` 符号链接，并通过符号链接访问实际文件。

学习自：[What？你还不明白npm, yarn, pnpm之间的区别？！](https://juejin.cn/post/7433427781928386571)



#### pnpm 与其他包管理工具的比较

##### 特性比较

| **特性**       | **npm**                              | **yarn**                               | **pnpm**                                      |
| -------------- | ------------------------------------ | -------------------------------------- | --------------------------------------------- |
| 依赖管理方式   | 扁平化管理，嵌套依赖树，可能重复安装 | 扁平化管理和符号链接，同版本只安装一次 | 基于硬链接和符号链接的内容寻址存储            |
| 安装速度       | 最慢                                 | 中等（并行安装）                       | 最快（得益于硬链接复用）                      |
| 磁盘空间占用   | 最大                                 | 中等                                   | 最小                                          |
| 依赖管理严格性 | 低（可能存在幽灵依赖）               | 中等                                   | 高（严格的依赖树结构）                        |
| 锁文件格式     | `package-lock.json`                  | `yarn.lock`                            | `pnpm-lock.yaml`                              |
| 缓存机制       | 基础缓存                             | 高效缓存                               | <font color=red>基于内容寻址的全局存储</font> |
| 并行安装能力   | 不支持 (npm5-) / 支持 (npm5+)        | 支持                                   | 支持                                          |
| 依赖提升策略   | 部分提升                             | 全量提升                               | 不提升（严格按照依赖声明）                    |
| workspace 支持 | 有限支持                             | 完整支持                               | 完整支持                                      |

##### 命令对比

| **操作**               | **npm**                        | **yarn**                          | **pnpm**                          |
| ---------------------- | ------------------------------ | --------------------------------- | --------------------------------- |
| 初始化项目             | `npm init`                     | `yarn init`                       | `pnpm init`                       |
| 自动确认默认选项初始化 | `npm init -y`                  | `yarn init -y`                    | `pnpm init`                       |
| 安装依赖               | `npm install`                  | `yarn`                            | `pnpm install`                    |
| 安装单个依赖           | `npm install <pkg>`            | `yarn add <pkg>`                  | `pnpm add <pkg>`                  |
| 安装特定版本           | `npm install <pkg>@<ver>`      | `yarn add <pkg>@<ver>`            | `pnpm add <pkg>@<ver>`            |
| 全局安装依赖           | `npm install -g <pkg>`         | `yarn global add <pkg>`           | `pnpm add -g <pkg>`               |
| 安装开发依赖           | `npm install <pkg> -D`         | `yarn add <pkg> -D`               | `pnpm add <pkg> -D`               |
| 更新依赖               | `npm update <pkg>`             | `yarn upgrade <pkg>`              | `pnpm update <pkg>`               |
| 卸载依赖               | `npm uninstall <pkg>`          | `yarn remove <pkg>`               | `pnpm remove <pkg>`               |
| 查看已安装依赖         | `npm list`                     | `yarn list`                       | `pnpm list`                       |
| 执行脚本               | `npm run <script>`             | `yarn <script>`                   | `pnpm run <script>`               |
| 安装指定注册源         | `npm install --registry <url>` | `yarn add <pkg> --registry <url>` | `pnpm add <pkg> --registry <url>` |
| 清理缓存               | `npm cache clean --force`      | `yarn cache clean`                | `pnpm store prune`                |
| 列出全局包             | `npm list -g --depth=0`        | `yarn global list`                | `pnpm list -g --depth=0`          |

摘自：[What？你还不明白npm, yarn, pnpm之间的区别？！](https://juejin.cn/post/7433427781928386571)



#### 特殊配置

`resolutions` 字段在 pnpm 10 中被废弃



#### Workspace

pnpm has <font color=dodgerBlue>built-in support for monorepositories</font>（👀 即 monorepo ），You can <font color=red>create a workspace to unite multiple projects inside a single repository</font>.

<font color=red>A workspace **must** have a [`pnpm-workspace.yaml`](https://pnpm.io/pnpm-workspace_yaml) file in its root</font>. A workspace also <font color=LightSeaGreen>**may** have an `.npmrc` in its root</font>.

##### Workspace protocol ( `workspace:` )

<font color=dodgerBlue>**By default**</font>, <font color=red>pnpm will **link packages from the workspace**</font> <font color=LightSeaGreen>if the available packages match the declared ranges</font>. For instance, <font color=red>`foo@1.0.0` is linked into `bar` **if `bar` has `"foo": "^1.0.0"` in its dependencies**</font> and <font color=fuchsia>`foo@1.0.0` is in the workspace</font>. However, if `bar` has `"foo": "2.0.0"` in dependencies and <font color=dodgerBlue>**`foo@2.0.0` is not in the workspace**</font>, `foo@2.0.0` will be installed from the registry（👀 注意与下面 workspace 的行为对比）. This behavior introduces some uncertainty（🌏 该行为将会引入不确定性）.

Luckily, <font color=red>**pnpm supports the `workspace:` protocol**</font>. <font color=dodgerBlue>When this protocol is used</font>, <font color=fuchsia>pnpm will **refuse to resolve to anything other than a local workspace package**</font>. So, <font color=dodgerBlue>**if you set `"foo": "workspace:2.0.0"`**</font> , <font color=fuchsia>**this time installation will fail** because `"foo@2.0.0"` isn't present in the workspace</font>.

This protocol is especially useful when the [link-workspace-packages](https://pnpm.io/npmrc#link-workspace-packages) option is set to `false` . <font color=dodgerBlue>In that case</font>, <font color=red>pnpm will only link packages from the workspace **if the `workspace:` protocol is used**</font>.

###### Referencing workspace packages through aliases

<font color=dodgerBlue>Let's say you have a package in the workspace named `foo`</font> . <font color=dodgerBlue>**Usually**</font>, <font color=red>you would reference it as `"foo": "workspace:*"`</font> .

If you want to use a different alias, the following syntax will work too: `"bar": "workspace:foo@*"` .

<font color=fuchsia>Before publish, **aliases are converted to regular aliased dependencies**</font>. The <font color=LightSeaGreen>above example will become: `"bar": "npm:foo@1.0.0"`</font> .

###### Referencing workspace packages through their relative path

In a workspace with 2 packages:

```diff
+ packages
    + foo
    + bar
```

`bar` may have `foo` in its dependencies declared as `"foo": "workspace:../foo"` . Before publishing, these specs are converted to regular version specs supported by all package managers.

###### Publishing workspace packages

When a workspace package is packed into an archive (whether it's through `pnpm pack` or one of the publish commands like `pnpm publish` ), <font color=dodgerBlue>we **dynamically replace** any `workspace:` dependency by</font>:

- The corresponding version in the target workspace (if you use `workspace:*` , `workspace:~` , or `workspace:^` )
- The associated semver range (for any other range type)

So for example, if we have `foo` , `bar` , `qar` , `zoo` in the workspace and they all are at version `1.5.0` , the following:

```json
{
    "dependencies": {
        "foo": "workspace:*",
        "bar": "workspace:~",
        "qar": "workspace:^",
        "zoo": "workspace:^1.5.0"
    }
}
```

<font color=dodgerBlue>Will be transformed into:</font>

```json
{
    "dependencies": {
        "foo": "1.5.0",
        "bar": "~1.5.0",
        "qar": "^1.5.0",
        "zoo": "^1.5.0"
    }
}
```

This feature allows you to depend on your local workspace packages while <font color=fuchsia>still being able to publish the resulting packages to the remote registry without needing intermediary publish steps</font> - <font color=red>your consumers will be able to use your published workspaces as any other package</font>, still benefitting from the guarantees semver offers.

摘自：[pnpm doc - Workspace](https://pnpm.io/workspaces#workspace-protocol-workspace)



#### Catalogs

> Added in: v9.5.0

"*Catalogs*" are a [workspace feature](https://pnpm.io/workspaces) for <font color=red>defining dependency **version ranges** as reusable constants</font>. Constants defined in catalogs can later be referenced in `package.json` files.

##### The Catalog Protocol (`catalog:`)

Once a catalog is defined in `pnpm-workspace.yaml` ,

```yaml
packages:
  - packages/*

# Define a catalog of version ranges.
catalog:
  react: ^18.3.1
  redux: ^5.0.1
```

The `catalog:` protocol can be used instead of the version range itself.

```json
// packages/example-app/package.json
{
  "name": "@example/app",
  "dependencies": {
    "react": "catalog:",
    "redux": "catalog:"
  }
}
```

<font color=red>This is equivalent to writing a version range (e.g. `^18.3.1`) directly</font>.

> 👀 下面是替换后的效果

```json
// packages/example-app/package.json
{
  "name": "@example/app",
  "dependencies": {
    "react": "^18.3.1",
    "redux": "^5.0.1"
  }
}
```

You may use the `catalog:` protocol in the next fields of your `package.json` :

- `dependencies`
- `devDependencies`
- `peerDependencies`
- `optionalDependencies`
- `pnpm.overrides`

The `catalog:` protocol <font color=red>allows an optional name after the colon (ex: `catalog:name`) to specify which catalog should be used</font>. When a name is omitted, the default catalog is used.

Depending on the scenario, the `catalog:` protocol offers a few [advantages](https://pnpm.io/catalogs#advantages) compared to writing version ranges directly that are detailed next.

##### Advantages

In a workspace (i.e. monorepo or multi-package repo) <font color=lightSeaGreen>it's common for the same dependency to be used by many packages</font>. <font color=lightSeaGreen>**Catalogs reduce duplication**</font> when authoring `package.json` files and <font color=dodgerBlue>provide a few benefits in doing so</font>:

> 👀 感觉和定义全局变量、定义宏变量，然后使用的好处差不多

- **Maintain unique versions** — It's usually <font color=red>desirable to have only one version of a dependency in a workspace</font>. Catalogs make this easier to maintain. Duplicated dependencies can conflict at runtime and cause bugs. Duplicates also increase size when using a bundler.
- **Easier upgrades** — When upgrading a dependency, <font color=red>only the catalog entry in `pnpm-workspace.yaml` needs to be edited</font> rather than all `package.json` files using that dependency. This saves time — only one line needs to be changed instead of many.
- **Fewer merge conflicts** — Since `package.json` files do not need to be edited when upgrading a dependency, git merge conflicts no longer happen in these files.

##### Defining Catalogs

Catalogs are defined in the `pnpm-workspace.yaml` file. <font color=dodgerBlue>There are two ways to define catalogs</font>.

1. Using the (<font color=dodgerBlue>singular</font>) <font color=red>**`catalog`**</font> field to <font color=red>create a catalog **named `default`**</font> .
2. Using the (<font color=dodgerBlue>plural</font>) <font color=red>**`catalogs`**</font> field to <font color=red>create **arbitrarily named** catalogs</font>.

> [!TIP]
>
> If you have an existing workspace that you want to migrate to using catalogs, you can use the following [codemod](https://go.codemod.com/pnpm-catalog):
>
> ```sh
> pnpx codemod pnpm/catalog
> ```

###### Default Catalog

The top-level `catalog` field allows users to define a catalog named `default`.

```yaml
# pnpm-workspace.yaml
catalog:
  react: ^18.2.0
  react-dom: ^18.2.0
```

These version ranges can be referenced through `catalog:default`. For the default catalog only, a special `catalog:` shorthand can also be used. Think of <font color=red>`catalog:` as a shorthand that expands to `catalog:default`</font> .

###### Named Catalogs

Multiple catalogs with arbitrarily chosen names can be configured under the `catalogs` key.

```yaml
# pnpm-workspace.yaml
catalogs:
  # Can be referenced through "catalog:react17"
  react17:
    react: ^17.0.2
    react-dom: ^17.0.2

  # Can be referenced through "catalog:react18"
  react18:
    react: ^18.2.0
    react-dom: ^18.2.0
```

<font color=red>A default catalog can be defined **alongside** multiple named catalogs</font>. This might be useful in a large multi-package repo that's migrating to a newer version of a dependency piecemeal.

```yaml
# pnpm-workspace.yaml
catalog:
  react: ^16.14.0
  react-dom: ^16.14.0

catalogs:
  # Can be referenced through "catalog:react17"
  react17:
    react: ^17.0.2
    react-dom: ^17.0.2

  # Can be referenced through "catalog:react18"
  react18:
    react: ^18.2.0
    react-dom: ^18.2.0
```

###### Publishing

<font color=red>The `catalog:` protocol is removed when running `pnpm publish` or `pnpm pack`</font> . This is similar to the [`workspace:` protocol](https://pnpm.io/workspaces#workspace-protocol-workspace), which is [also replaced on publish](https://pnpm.io/workspaces#publishing-workspace-packages).

For example,

```json
// packages/example-components/package.json
{
  "name": "@example/components",
  "dependencies": {
    "react": "catalog:react18",
  }
}
```

Will become the following on publish.

```json
{
  "name": "@example/components",
  "dependencies": {
    "react": "^18.3.1",
  }
}
```

The `catalog:` protocol replacement process allows the `@example/components` package to be used by other workspaces or package managers.

##### Caveats

The <font color=red>`pnpm update` command does not yet support catalogs</font>.

<font color=dodgerBlue>To update dependencies defined in `pnpm-workspace.yaml`</font> , <font color=red>**newer version ranges will need to be chosen manually until a future version of pnpm handles this**</font>.

摘自：[pnpm doc - Feature - Catalogs](https://pnpm.io/catalogs)



#### `pnpm-workspace.yaml`

`pnpm-workspace.yaml` <font color=red>**defines the root of the [workspace](https://pnpm.io/workspaces)**</font> and enables you to include / exclude directories from the workspace. <font color=dodgerBlue>By default</font>, <font color=lightSeaGreen>all packages of all subdirectories are included</font>.

For example:

```yaml
# pnpm-workspace.yaml
packages:
  # specify a package in a direct subdir of the root
  - 'my-app'
  # all packages in direct subdirs of packages/
  - 'packages/*'
  # all packages in subdirs of components/
  - 'components/**'
  # exclude packages that are inside test directories
  - '!**/test/**'
```

The root package is always included, even when custom location wildcards are used.

Catalogs are also defined in the `pnpm-workspace.yaml` file. See [*Catalogs*](https://pnpm.io/catalogs) for details.

```yaml
packages:
  - 'packages/*'

catalog:
  chalk: ^4.1.2

catalogs:
  react16:
    react: ^16.7.0
    react-dom: ^16.7.0
  react17:
    react: ^17.10.0
    react-dom: ^17.10.0
```

摘自：[pnpm doc - pnpm-workspace.yaml](https://pnpm.io/pnpm-workspace_yaml)



#### pnpm 过滤 `--filter`

// TODO

[pnpm doc - Filtering](https://pnpm.io/zh/filtering)



#### 幽灵（幻影）依赖

[幻影依赖【渡一教育】](https://www.bilibili.com/video/BV1UN4y1k7Ce)



#### global virtual store

> 💡 可以看下
>
> - [pnpm doc - Settings (pnpm-workspace.yaml) # enableGlobalVirtualStore](https://pnpm.io/settings#enableglobalvirtualstore)
> - [pnpm 10.12 Introduces Global Virtual Store and Expanded Version Catalogs](https://socket.dev/blog/pnpm-introduces-global-virtual-store-and-expanded-version-catalogs)

##### 官方文档中的介绍

- Default: **false** (always **false** in CI)
- Type: **Boolean**
- Status: **Experimental**

<font color=dodgerBlue>When enabled</font>, <font color=red>`node_modules` contains only **symlinks** to a central virtual store</font>, <font color=dodgerBlue>rather than</font> <font color=lightSeaGreen>to `node_modules/.pnpm`</font> . <font color=dodgerBlue>By default</font>, this central store is located at `<store-path>/links` (use `pnpm store path` to find `<store-path>`).

<font color=dodgerBlue>In the central virtual store</font>, <font color=red>each package is hard linked into a directory whose name is the hash of its dependency graph</font>. As a result, all projects on the system can symlink their dependencies from this shared location on disk. This approach is conceptually similar to how [NixOS manages packages](https://nixos.org/guides/how-nix-works/), using dependency graph hashes to create isolated and shareable package directories in the Nix store.

> This should not be confused with the global content-addressable store. The actual package files are still <font color=red>hard linked from the content-addressable store</font>—but instead of being linked directly into `node_modules/.pnpm`, they are linked into the global virtual store.

Using a global virtual store can significantly speed up installations when a warm cache is available. <font color=dodgerBlue>However, in CI environments (where caches are typically absent)</font>, <font color=lightSeaGreen>it may slow down installation</font>. <font color=dodgerBlue>If pnpm detects that it is running in CI</font>, <font color=red>this setting is automatically disabled</font>.

摘自：[pnpm doc - Settings (pnpm-workspace.yaml) # enableGlobalVirtualStore](https://pnpm.io/settings#enableglobalvirtualstore)



### pnpm 命令

#### `pnpm env <cmd>`

管理 Node.js 环境。💡 类似于 nvm 和 n 等包管理工具

##### 命令行

安装并使用指定版本的 Node.js。

###### 安装 LTS 版本的 Node.js

```bash
pnpm env use --global lts
pnpm env use --global argon
```

###### 安装 v16 的Node.js

```bash
pnpm env use --global 16
```

###### 安装 Node.js 的预发行版本

```bash
pnpm env use --global nightly
pnpm env use --global rc
pnpm env use --global 16.0.0-rc.0
pnpm env use --global rc/14
```

###### 安装最新版本的 Node.js

```bash
pnpm env use --global latest
```

##### 配置项

- `--global` , `-g`：此更改将全局生效。

摘自：[pnpm doc - `pnpm env <cmd>`](https://pnpm.io/zh/cli/env)



## Yarn

#### `.yarnrc`

官方文档见 [yarn doc - yarnrc](https://yarnpkg.com/configuration/yarnrc)

##### `npmRegistryServer`

用于定义 npm registry 的地址。

<font color=red>Define the registry to use when fetching packages.</font>

<font color=dodgerBlue>Should you want to define different registries for different scopes</font>, see `npmScopes`. To define the authentication scheme for your servers, see `npmAuthToken`. <font color=lightSeaGreen>**The url must use HTTPS by default**</font>, but this can be changed by adding it to the `unsafeHttpWhitelist` .

```yaml
npmRegistryServer: "https://registry.yarnpkg.com",
```

###### Per-scope registry configurations.

```yaml
npmScopes: {
  my-company: {
    npmPublishRegistry: See npmPublishRegistry,
    npmRegistryServer: See npmRegistryServer,
    npmAlwaysAuth: See npmAlwaysAuth,
    npmAuthIdent: See npmAuthIdent,
    npmAuthToken: See npmAuthToken,
  },
},
```

摘自：[Yarn doc - yarnrc#npmRegistryServer](https://yarnpkg.com/configuration/yarnrc#npmRegistryServer)

> 💡 补充
>
> Gemini 2.0 的解释
>
> <img src="https://s2.loli.net/2025/01/07/Ed39rxoKvkqubJs.png" alt="image-20250107222309977" style="zoom:45%;" />
>
> <img src="https://s2.loli.net/2025/01/07/A5RqXZyGWsBor6D.png" alt="image-20250107222545689" style="zoom:45%;" />
>
> <img src="https://s2.loli.net/2025/01/07/njl1Ld5qtEbW9Gh.png" alt="image-20250107222633822" style="zoom:45%;" />



##### `.yarnrc` vs `.yarnrc.yml`

`.yarnrc` 和 `.yarnrc.yml` 都是 Yarn 配置文件。不过，`.yarnrc` 只能在 Yarn v1 中使用，不兼容更高版本； `.yarnrc.yml` 虽然也可以在 Yarn v1 中使用，但是更推荐在 v2+ 版本中使用，因为其“使用 YAML 语法，配置更易读、易维护，支持更复杂的配置选项”。

> 💡 补充
>
> Gemini 2.0 的解释
>
> <img src="https://s2.loli.net/2025/01/07/qwRVLegaxAItup4.png" alt="image-20250107221304498" style="zoom: 45%;" />

###### 群友的经历与经验

> 在 M1 电脑上跑 taro2 项目的时候出现了安装 node-sass 的问题，主要原因是本地电脑环境存在 2 个 python 环境，Python2 和 Python3, 编译 node-sass 需要使用 Python2，但是默认会使用 Python3，始终编译不过，折腾了大半天
> 最后在同事的提醒下，在项目根目录下的 `.yarnrc` 中指定下 python 路径就好了。
>
> 来自：CodingStartup 群友

当然：类似的，在 `.npmrc` 中应该也是生效的


#### yarn 命令

###### 升级 yarn

```bash
yarn set version stable
```

将 yarn 更新到最新，一般用于将 yarn 从 v1 升级到最新版本



#### 特殊配置

##### `resolutions`

Override the resolutions of specific dependencies.

This field allows you to instruct Yarn to use a specific resolution (specific package version) instead of anything the resolver would normally pick. This is <font color=lightSeaGreen>useful to enforce all your packages to use a single version of a dependency, or **backport a fix**</font>. The syntax for the resolution key accepts one level of specificity, <font color=dodgerBlue>so all the following examples are correct</font>.

<font color=dodgerBlue>**Note**</font> : When a path is relative, like it can be with the `file:` and `portal:` protocols, it is resolved relative to the path of the project.

<font color=dodgerBlue>**Note**</font> : <font color=lightSeaGreen>The `resolutions` field **can only be set at the root of the project**</font>, and will generate a warning if used in any other workspace.

```json
"resolutions": {
  "relay-compiler": "3.0.0",
  "webpack/memory-fs": "0.4.1",
  "@babel/core/json5": "2.1.0",
  "@babel/core/@babel/generator": "7.3.4",
  "@babel/core@npm:7.0.0/@babel/generator": "7.3.4",
},
```

摘自：[yarn doc - configuration - manifest](https://yarnpkg.com/configuration/manifest)



#### PnP

通过“沉浸式翻译” GPT-4 翻译浏览了一下 https://classic.yarnpkg.com/en/docs/pnp/ 的内容。不过，感觉自己对于 pnpm 的类似机制并不了解，所以 PnP 看起来也是有些困难，有空可以再看一遍，并做一下笔记...

另外，还有 [Yarn 的 Plug'n'Play 特性](https://loveky.github.io/2019/02/11/yarn-pnp/) ，看完了感觉很不错，官方文档的介绍偏理论，这篇偏实践。

###### 补充介绍

> `yarn` 在 `v2` 中推出了 `PnP` 机制，抛弃 `node_modules` 目录，<font color=red>直接从 `.pnp.js` 加载依赖，加速启动速度，并减少磁盘文件数量</font>，你<font color=red>可以将 `.yarn/cache` 和 `.pnp.js` 一起提交到 `git`</font> ，这样 `clone` 项目后无需再执行 `install` ，即装即用!
>
> 摘自：[pnpm 的正确打开方式，怎么在保留 git 历史信息的情况下，将前后端项目保存在一个 git 仓库里？](https://mp.weixin.qq.com/s/lhvkIiNG2dkmkY80UIkAig)



## Babel

##### 一些资料

- [Babel 官网](https://babel.dev)
- [babel-handbook](https://github.com/jamiebuilds/babel-handbook)

- [神说要有光 - Babel 插件通关秘籍 ](https://juejin.cn/book/6946117847848321055/section) 这也是这里 Babel 笔记的主要摘抄



### 《Babel 插件通关秘籍》笔记



#### Babel 介绍

babel 是 JS 的转译器 (  JavaScript Transpiler ) 👀 详见 [[#编译器和转译器]]

##### 命名演化

babel 最开始叫 6to5，顾名思义是 es6 转 es5，但是后来随着 es 标准的演进，有了 es7、es8 等， 6to5 的名字已经不合适了，所以改名为了 babel。

##### Babel 的三种用途

###### 转译 ES Next、TypeScript、Flow 等到目标环境支持的 js

这个是<font color=red>最常用的功能</font>，用来把代码中的 ES Next 的新的语法、TypeScript 和 Flow 的语法转成基于目标环境支持的语法的实现。并且还可以把目标环境不支持的 api 进行 polyfill 。

> 💡 还有 jsx 的编译

<font color=red>babel7 提供了 `@babel/preset-env` 的包</font>，可以<font color=red>指定目标 env 来按需转换，转换更加的精准，产物更小</font>。

###### 一些特定用途的代码转换

babel 是一个转译器，暴露了很多 api，用这些 api 可以完成<font color=red>代码到 AST 的解析、转换、以及目标代码的生成</font>。

<font color=dodgerBlue>开发者可以用它来完成一些特定用途的转换</font>，比如<font color=red>函数插桩</font>（<font color=red>函数中自动插入一些代码</font>，例如<font color=red>埋点代码</font>）、<font color=red>自动国际化</font>等。<font color=LightSeaGreen>流行的小程序转译工具 taro，就是基于 babel 的 api 来实现的</font>。

###### 代码的静态分析

<font color=red>对代码进行 parse 之后，会生成 AST，通过 AST 能够理解代码结构</font>，除了转换 AST 再打印成目标代码之外，也同样<font color=red>可以**用于分析代码的信息，进行一些静态检查**</font>。

- <font color=red>linter 工具</font>就是分析 AST 的结构，对代码规范进行检查。
- <font color=LightSeaGreen>api 文档自动生成工具</font>，可以提取源码中的注释，然后生成文档。
- <font color=red>type checker</font> 会根据从 AST 中提取的或者推导的类型信息，对 AST 进行类型是否一致的检查，从而减少运行时因类型导致的错误。👀 比如 tsc
- <font color=red>压缩混淆工具</font>，这个也是分析代码结构，进行删除死代码、变量名混淆、常量折叠等各种编译优化，生成体积更小、性能更优的代码。
- JS 解释器，除了对 AST 进行各种信息的提取和检查以外，我们<font color=red>还可以直接解释执行 AST</font>。



#### Babel 的编译流程

##### 编译器和转译器

编译的定义就是从一种编程语言转成另一种编程语言。主要指的是高级语言到低级语言。

<font color=LightSeaGreen>一般编译器 Compiler 是指高级语言到低级语言的转换工具</font>。而<font color=fuchsia>从 **高级语言** 到 **高级语言** 的 **转换工具**，被叫做 <font size=4>**转换编译器**</font>，简称 **转译器** ( Transpiler )</font>。Babel 就是一个 JavaScript Transpiler。

##### Babel 的编译流程

<font color=fuchsia>Babel 是 **source to source 的转换**</font>，整体编译流程分为三步：

- **parse**：通过 <font color=red>parser 把源码转成抽象语法树 ( AST )</font>
- **transform**：<font color=red>遍历 AST，调用各种 transform 插件对 AST 进行增删改</font>
- **generate**：把<font color=red>转换后的 AST 打印</font>（👀 生？）<font color=red>成目标代码</font>，并 <font color=fuchsia size=4>**生成 sourcemap**</font>

![img](https://s2.loli.net/2023/01/03/79luiCsc6EPqxfA.png)

##### 为什么 babel 的编译流程会分 parse、transform、generate 这 3 步

源码是一串按照语法格式来组织的字符串，<font color=LightSeaGreen>人能够认识，但是计算机并不认识</font>；<font color=red>想让计算机认识就要转成一种数据结构，通过不同的对象来保存不同的数据，并且按照依赖关系组织起来</font>；这种数据结构就是抽象语法树 ( abstract syntax tree )。

之所以叫“抽象”语法树是因为<font color=red>数据结构中省略掉了一些无具体意义的分隔符比如 `;` `{` `}`等</font> 

> 💡 参考 [编程语言的发展趋势：从没有分号，到DSL](https://mp.weixin.qq.com/s/_SOlzlLG6ua8kXxnPltX0g) 中所说：
>
> > 在大多数情况下，分号是给机器看的，而不是给人看的。**写分号，本质是我们人类在迁就编译器**，毕竟，机器是很傻的。
>
> 类似的，`{}` 括号也是。

有了 AST，计算机就能理解源码字符串的意思，而理解是能够转换的前提，所以编译的第一步需要把源码 parse 成 AST。

转成 AST 之后就可以通过修改 AST 的方式来修改代码，<font color=red>这一步会遍历 AST 并进行各种增删改</font>，<font color=LightSeaGreen>这一步也是 babel 最核心的部分</font>。

经过转换以后的 AST 就是符合要求的代码，就可以再转回字符串，<font color=red>转回字符串的过程中把之前删掉的一些分隔符再加回来</font>。

<font color=dodgerBlue>**简单总结**</font>：**为了让计算机理解代码需要先对源码字符串进行 parse，生成 AST，把对代码的修改转为对 AST 的增删改，转换完 AST 之后再打印成目标代码字符串。**

##### parse、transform、generate 三步做了什么

###### parse

parse 阶段的目的是把源码字符串转换成机器能够理解的 AST，这个过程<font color=fuchsia>分为 **词法分析**、**语法分析**</font>。

比如 `let name = 'guang';` 这样一段源码，我们要<font color=red>先把它分成一个个不能细分的单词</font> ( token )，也就是 `let` , `name` , `=` , `'guang'` ，<font color=fuchsia>这个过程是 **词法分析**</font>，按照单词的构成规则来拆分字符串成单词。

之后要<font color=fuchsia>把 token 进行递归的组装，生成 AST</font>，<font color=fuchsia>这个过程是 **语法分析**</font>；按照不同的语法结构，来把一组单词组合成对象，比如<font color=red>声明语句、赋值表达式等都有对应的 AST 节点</font>。

<img src="https://s2.loli.net/2023/01/03/2r3SovJbGRWmuAx.png" alt="img" style="zoom:35%;" />

###### transform

transform 阶段是对 parse 生成的 AST 的处理，会<font color=red>进行 AST 的遍历</font>，<font color=red>遍历的过程中处理到不同的 AST 节点会</font> <font color=fuchsia>调用注册的 **相应的 visitor 函数**</font>，<font color=red>visitor 函数里可以对 AST 节点进行增删改，返回新的 AST</font>（可以指定是否继续遍历新生成的 AST）。这样遍历完一遍 AST 之后就完成了对代码的修改。

<img src="https://s2.loli.net/2023/01/03/FkptO2ITlQL1vnA.png" alt="img" style="zoom:40%;" />

###### generate

generate 阶段会把 AST 打印成目标代码字符串，并且会生成 sourcemap。<font color=fuchsia>不同的 AST 对应的不同结构的字符串</font>，比如 <font color=red>`IfStatement` 就可以打印成 `if (test) {}` 格式的代码</font>。这样从 AST 根节点进行递归的字符串拼接，就可以生成目标代码的字符串。

<img src="https://s2.loli.net/2023/01/03/F2IV9cSkPGs4NfC.png" alt="img" style="zoom:35%;" />

sourcemap 记录了源码到目标代码的转换关系，通过它我们可以找到目标代码中每一个节点对应的源码位置，用于调试的时候把编译后的代码映射回源码，或者线上报错的时候把报错位置映射到源码。



#### Babel 的 AST

AST 是对源码的抽象，<font color=red>字面量、标识符、表达式、语句、模块语法、class 语法都有各自的 AST</font>。

##### Literal 字面量

`let name = 'guang'` 中，`'guang'` 就是一个字符串字面量 StringLiteral，相应的还有数字字面量 NumericLiteral ，布尔字面量 BooleanLiteral ，字符串字面量 StringLiteral，正则表达式字面量 RegExpLiteral 等。

下面这些字面量都有对应的 Literal 节点：

<img src="https://s2.loli.net/2023/01/23/GBczVNK6COvZX4l.png" alt="" style="zoom: 33%;" />

代码中的字面量很多，babel 就是通过 xxLiteral 来抽象这部分内容的。

##### Identifier

Identifer 是标识符的意思，变量名、属性名、参数名等各种声明和引用的名字，都是 Identifer。



#### Babel 的 API

<font color=lightSeaGreen>babel 的编译流程分为三步：parse、transform、generate</font>，<font color=dodgerBlue>每一步都暴露了一些 api 出来</font>。

- <font color=dodgerBlue>**parse 阶段**</font> 有 <font color=lightSeaGreen>**`@babel/parser`**</font> ，功能是<font color=red>把源码转成 AST</font>
- <font color=dodgerBlue>**transform 阶段**</font> 有 <font color=lightSeaGreen>**`@babel/traverse`**</font> ，可以<font color=red>遍历 AST</font>，并<font color=red>调用 visitor 函数修改 AST</font>，<font color=dodgerBlue>**修改 AST** 自然涉及到 AST 的判断、创建、修改等</font>，这时候就需要 <font color=lightSeaGreen>**`@babel/types`**</font> 了，当需要<font color=dodgerBlue>**批量创建 AST**</font> 的时候可以使用 <font color=lightSeaGreen>**`@babel/template`**</font> 来简化 AST 创建逻辑。
- <font color=dodgerBlue>**generate 阶段**</font> 会<font color=red>把 AST 打印为目标代码字符串</font>，同时<font color=red>生成 sourcemap</font>，需要 <font color=lightSeaGreen>**`@babel/generator`**</font> 包
- <font color=dodgerBlue>**中途遇到错误想打印代码位置**</font> 的时候，使用 <font color=lightSeaGreen>**`@babel/code-frame`**</font> 包
- <font color=dodgerBlue>**babel 的整体功能**</font> 通过 <font color=lightSeaGreen>**`@babel/core`**</font> 提供，基于上面的包完成 babel 整体的编译流程，并<font color=red>应用 plugin 和 preset</font>。

##### `@babel/parser`

babel parser 叫 babylon，是基于 acorn 实现的，扩展了很多语法，可以支持 es next、jsx、flow、typescript 等语法的解析。

<font color=lightSeaGreen>babel parser **默认只能 parse js 代码**</font>，<font color=red>jsx、flow、typescript 这些非标准的语法的解析需要指定语法插件</font>。

<font color=dodgerBlue>它提供了有两个 api</font>：<font color=red>parse 和 parseExpression</font>。两者都是把源码转成 AST，不过 <font color=dodgerBlue>parse</font> <font color=red>返回的 **AST 根节点是 File**（整个 AST）</font>，<font color=dodgerBlue>parseExpression</font> <font color=red>返回的 AST 根节点是是 Expression（表达式的 AST）</font>，粒度不同。

```ts
function parse(input: string, options?: ParserOptions): File
function parseExpression(input: string, options?: ParserOptions): Expression
```

详细的 `options` 可以查看 [文档](https://babeljs.io/docs/babel-parser#options)。其实<font color=dodgerBlue>**主要分为两类**</font>，一是 **parse 的内容是什么**，二是 **以什么方式去 parse**

###### parse 的内容是什么

- `plugins` ：指定jsx、typescript、flow 等插件来解析对应的语法

- `allowXxx` ：指定一些语法是否允许，比如函数外的 await、没声明的 export等

- `sourceType` ：指定是否支持解析模块语法，有 `module` 、`script` 、`unambiguous` 3个取值：

  - `module` ：解析 es module 语法
  - `script` ：不解析 es module 语法
  - `unambiguous` ：根据内容是否有 import 和 export 来自动设置 module 还是 script

  一般会指定 `sourceType` 为 `unambiguous`

```js
const  parser = require('@babel/parser');

const ast = parser.parse("代码", {
    sourceType: 'unambiguous',
    plugins: ['jsx']
});
```

###### 以什么方式 parse

- `strictMode` ：是否是严格模式
- `startLine` ：从源码哪一行开始 parse
- `errorRecovery` ：出错时是否记录错误并继续往下 parse
- `tokens` ：parse 的时候是否保留 token 信息
- `ranges` ：是否在 ast 节点中添加 `ranges` 属性

用 astexplorer.net 来查看 AST 的时候，也同样支持 parser options 的设置：

<img src="https://s2.loli.net/2024/11/28/aPJESXKlZ8p7wnv.png" alt="image-20241128164148621" style="zoom:40%;" />



### 其他补充

##### babel-plugin-import

在看 [不要再写满屏import导入啦！🔥](https://juejin.cn/post/7344571285848768524) 看到了 [babel-plugin-import](https://github.com/umijs/babel-plugin-import) 有点好奇，便准备了解一下：

<img src="https://s2.loli.net/2024/03/24/1xdvFNBIOMZmfQA.png" alt="image-20240324000541259" style="zoom:50%;" />

“减少最终打包的体积” 感觉和 Tree Shaking 很像。不过 Tree Shaking 只支持 ESM，而 `babel-plugin-import` 不是，这就提高了适用范围。

<img src="https://s2.loli.net/2024/03/24/O7THxzYfIDL2lJR.png" alt="image-20240324000743392" style="zoom:50%;" />



## PostCSS

> 💡 PostCSS 具有丰富的插件生态，详见 [[#插件有哪些？]]

#### 峰华前端的《13 分钟掌握 PostCSS》笔记

PostCSS 是专门用于处理 CSS 的工具，通过一系列的插件来修改最终样式：可以让开发者使用最新的 CSS 特性（哪怕提案处于 stage 0，配置示例见下面代码）提高开发效率（通过使用 [PostCSS-Preset-env](https://github.com/csstools/postcss-preset-env) 。不过原库已经 archived，并入了 [postcss-plugins](https://github.com/csstools/postcss-plugins) 。另外，所有 staged 的 CSS 特性，见 [postcss-preset-env - feature](https://preset-env.cssdb.org/features/) ）；也可以转译 CSS，兼容大多数浏览器（类似于 Babel ）；PostCSS 通过插件，支持 Sass 之类 CSS 预处理工具。

使用 [autoprefixer](https://github.com/postcss/autoprefixer) 可以查看哪些 CSS 属性、值 、选择器、`@rules` 是需要加上浏览器前缀的，使用 `npx autoprefixer --info` 即可输出内容，输出内容略。

使用 PostCSS 命令行工具 [PostCSS CLI](https://github.com/postcss/postcss-cli) 可以通过命令行的方式运行 PostCSS：

```sh
npx postcss input.css -o output.css -u yourPostCssPlugin
```

通用的语法见 [PostCSS CLI - README](https://github.com/postcss/postcss-cli) 。不过这样过于麻烦，可以通过 配置文件（配置 `postcss.config.js` 文件） 的方法，设置 `yourPostCssPlugin` ；使得即使在不使用 webpack 之类工具的情况下，至少不需要输入 `-u yourPostCssPlugin` 。使用 npm scripts 甚至可以省去前面（固定）的代码

```js
// postcss.config.js
const postcssPresetEnv = require('postcss-preset-env')

module.exports = {
  plugins: [
    require('stylelint'),
    require('autoprefixer'),
    postcssPresetEnv({
      stage: 0 // 可以使用提案在 stage 0 的新特性
    }),
    require('postcss-pxtorem')
  ]
}
```

CSS 也有自己的 lint 工具  [stylelint](https://github.com/stylelint/stylelint) 以及 它基本的规则 [stylelint-config-standard](https://github.com/stylelint/stylelint-config-standard) ；使用 stylelint 创建 `.stylelintrc.json` 配置文件，并在 `postcss.config.js` 配置文件中注册（注册见上面）：

```json
// .stylelintrc.json
{
  "extends": "stylelint-config-standard"
}
```

在开发时需要将 px 转换为 rem，这时候可以使用插件 [postcss-pxtorem](https://github.com/cuth/postcss-pxtorem) （类似的有 [px2rem](https://github.com/songsiqi/px2rem) ），不过前者 Star 更多

学习自：[13 分钟掌握 PostCSS](https://bilibili.com/video/BV1Pd4y1S7Mp)

相关的，在 [[Vue3 + TS 学习笔记#PostCSS 工具]] 中也有 PostCSS 的笔记

### Tecvan《零基础理解 PostCSS 的主流程》笔记

官网说：“PostCSS，一个使用 JavaScript 来处理 CSS 的框架” ( A tool for transforming CSS with JavaScript )。这句话高度概括了 PostCSS 的作用，但是太抽象了。按我理解，PostCSS 主要做了三件事：

1. **parse**：<font color=red>把 CSS 文件的字符串解析成抽象语法树 ( Abstract Syntax Tree ) 的框架</font>，<font color=fuchsia>解析过程中会检查 CSS 语法是否正确，不正确会给出错误提示</font>。
2. **runPlugin**：<font color=fuchsia>**执行插件函数**</font>。<font color=fuchsia>**PostCSS 本身不处理任何具体任务**，它提供了以特定属性或者规则命名的事件</font>。有特定功能的插件（如 autoprefixer、CSS Modules ）会注册事件监听器。PostCSS 会在这个阶段，重新扫描 AST，执行注册的监听器函数。
3. **generate**：<font color=fuchsia>插件对 AST 处理后，PostCSS 把处理过的 AST 对象转成 CSS string</font>。

![图片](https://s2.loli.net/2022/08/11/RDNvjWZ72KdySeh.png)

<font color=red>**「如果没有插件」**，那么初始传入的 CSS string 和 generate 生成的 CSS string 是一样的</font>。由此可见，<font color=fuchsia>PostCSS 本身并不处理任何具体的任务，只有当我们为其附加各种插件之后，它才具有实用性</font>。

下面分别详细分析三个阶段做的事。

#### 第一阶段：parse

<font color=dodgerBlue>CSS 规则集 ( rule-set ) 由选择器和声明块组成</font>：

![图片](https://s2.loli.net/2022/08/12/Z9Dtvd1efCRGJhP.png)

- **选择器** 指向您需要设置样式的 HTML 元素
- <font color=red>**声明块** 包含一条或多条用分号分隔的声明</font>
- 每条 **声明** 都包含一个 CSS 属性名称和一个值，以冒号分隔
- 多条 **CSS 声明** 用分号分隔，声明块用花括号括起来

##### 五类对象

<font color=fuchsia>AST 用 **五类对象** 描述 CSS 语法</font>。<font color=dodgerBlue>这里举个具体的例子，再打印出对应的 AST 结果，**对照了解 AST 五类对象和 CSS 语法的对应关系**</font>。

`app.css` 文件中写如下内容：

```css
@import url('./app-02.css');

.container {
  color: red;
}
```

##### Declaration 对象

<font color=fuchsia>Declaration 对象用来 **描述 CSS 中的每一条声明语句**</font>

- **type**：<font color=red>标记当前对象的类型</font>
- **parent**：<font color=red>记录父对象的实例</font>
- **prop**：记录声明中的属性名
- **value**：记录声明中的值
- **raws**：<font color=red>字段记录声明前的字符串、声明属性和值之间的符号的字符串</font>
- 其余字段（比如 `source` 及其子字段、`Symbol(prop)` ）解释见代码中的注释

上边 CSS 文件中的 `color: red;` 会被描述成如下对象：

```json
{
  parent: Rule,    // 外层的选择器被转译成 Rule 对象，是当前声明对象的 parent
  prop: "color",   // prop 字段记录声明的属性
  raws: {          // raws 字段记录声明前、后的字符串，声明属性和值之间的字符串，以及前边语句是否分号结束。
    before: '\n ', // raws.before 字段记录声明前的字符串
    between: ': ', // raws.between 字段记录声明属性和值之间的字符串
  },
  source: { // source 字段记录声明语句的开始、结束位置，以及当前文件的信息
    start: { offset: 45, column: 3, line: 4 },
    end: { offset: 55, column: 13, line: 4 },
    input: Input {
      css: '@import url('./app-02.css');\n\n.container {\n  color: red;\n}',
      file: '/Users/admin/temp/postcss/app.css',
      hasBOM: false,
      Symbol(fromOffsetCache): [0, 29, 30, 43, 57]
    }
  },
  Symbol('isClean'): false,  // Symbol(isClean) 字段默认值都是 false，用于记录当前对象关联的 plugin 是否执行。plugin 会在后续解释
  Symbol('my'): true, // Symbol(my) 字段默认值都是 true，用于记录当前对象是否是对应对象的实例，如果不是，可以根据类型把对象的属性设置为普通对象的 prototype 属性
  type: 'decl',      // type 记录对象类型，是个枚举值，声明语句的 type 固定是 decl
  value: "red"       // value 字段记录声明的值
}
```

##### Rule 对象

<font color=fuchsia>Rule 对象是 **描述选择器** 的</font>

- **type**：记录对象的类型
- **parent**：记录父对象的实例
- **nodes**：<font color=red>记录子对象的实例</font>
- **selector**：<font color=red>记录选择器的字符串</font>
- **raws**：<font color=red>记录选择器前的字符串、选择器和大括号之间的字符串、最后一个声明和结束大括号之间的字符串</font>
- 其余字段解释见代码中的注释

上边 `app.css` 文件中 `.container` 经过 postcss 转译后的对象是（每个字段的含义和功能已经以注释的形式进行了解释）：

```json
{
  nodes: [Declaration],  // nodes 记录包含关系，Rule 对象包含 Declaration 对象
  parent: Root,          // 根对象是 Root 对象，是当前声明对象的 parent
  raws: {                // raws 字段记录如下
    before: '\n\n',      // raws.before 字段记录选择器前的字符串
    between: ' ',        // raws.between 字段记录选择器和大括号之间的字符串
    semicolon: true,     // raws.semicolon 字段记录前置声明语句是正常分号结束
    after: '\n'          // raws.after 字段记录最后一个声明和结束大括号之间的字符串
  },
  selector:'.container', // selector 记录 selector
  source: {              // source 字段记录选择器语句的开始、结束位置，以及当前文件的信息
    start: { offset: 30, column: 1, line: 3 },
    input: Input {
      css: '@import url('./app-02.css');\n\n.container {\n  color: red;\n}',
      file: '/Users/admin/temp/postcss/app.css',
      hasBOM: false,
      Symbol(fromOffsetCache): [0, 29, 30, 43, 57]
    },
    end: { offset: 57, column: 1, line: 5 }
  },
  Symbol('isClean'): false, // Symbol(isClean) 字段默认值都是 false，用于记录当前对象关联的 plugin 是否执行。plugin 会在后续解释
  Symbol('my'): true,       // Symbol(my) 字段默认值都是 true，用于记录当前对象是否是对应对象的实例，如果不是，可以根据类型把对象的属性设置为普通对象的 prototype
  type: 'rule'              // type 记录对象类型，是个枚举值，声明语句的 type 固定是 rule
}
```

##### AtRule 对象

<font color=fuchsia>CSS 中除了选择器，还有一类语法是 `@` 开头的</font>，例如 `@import`、`@keyframes`、`@font-face`，PostCSS 把这类语法解析成 AtRule 对象。👀 注：它本身的名字也叫 `@rules`

- **type**：记录当前对象的类型
- **parent**：记录当前对象的父对象
- **name**：记录 <font color=red>`@` 紧跟着的单词</font>
- **params**：记录 name 对应的值

例如 `@import url("./app-02.css");` 将被解析成如下对象：

```json
{
  name: "import",                // name 记录 @ 紧跟着的单词
  params: "url('./app-02.css')", // params 记录 name 对应的值
  parent: Root,                  // parent 记录父对象
  raws: {                        // raws 字段记录如下
    before: '',                  // raws.before 记录 @语句前的空字符串
    between: '',                 // raws.between 记录 name 和 { 之间的空字符串
    afterName: '',               // raws.afterName 记录 name 和 @ 语句之间的空字符串
    after: '',                   // raws.after 记录大括号和上一个 rule 之间的空字符串
    semicolon: false             // raws.semicolon 上一个规则是否是分号结束
  },
  source: {                      // source 字段记录@语句的开始，以及当前文件的信息
    start: { offset: 0, column: 1, line: 1 },
    end: { offset: 27, column: 28, line: 1 },
    input: Input {
      css: '@import url('./app-02.css');\n\n.container {\n  color: red;\n}',
      file: '/Users/admin/temp/postcss/app.css',
      hasBOM: false,
      Symbol(fromOffsetCache): [0, 29, 30, 43, 57]
    }
  },
  Symbol('isClean'): false,  // Symbol(isClean) 字段默认值都是 false，用于记录当前对象关联的 plugin 是否执行。plugin 会在后续解释
  Symbol('my'): true,        // Symbol(my) 字段默认值都是 true，用于记录当前对象是否是对应对象的实例，如果不是，可以根据类型把对象的属性设置为普通对象的 prototype
  type: 'atrule'          // type 记录对象类型，是个枚举值，声明语句的 type 固定是 atrule
}
```

##### Comment 对象

<font color=fuchsia>CSS 文件中的注释被解析成 Comment 对象</font>。text 字段记录注释内容。`/* 你好 */  `被解析成：

```json
{
  parent: Root,    // parent 记录父对象
  raws: {          // raws 字段记录如下
    before: '',    // raws.before 记录注释语句前的空字符串
    left: ' ',     // raws.left 记录注释语句左侧的空字符串
    right: ' '     // raws.right 记录注释语句右侧的空字符串
  },
  source: {        // source 字段记录注释语句的开始、结束位置，以及当前文件的信息
    start: {…}, 
    input: Input, 
    end: {…}
  },
  Symbol('isClean'): false, // Symbol(isClean) 字段默认值都是 false，用于记录当前对象关联的 plugin 是否执行。plugin 会在后续解释
  Symbol('my'): true,       // Symbol(my) 字段默认值都是 true，用于记录当前对象是否是对应对象的实例，如果不是，可以根据类型把对象的属性设置为普通对象的 prototype
  text: '你好',              // text 记录注释内容
  type: 'comment'           // type 记录对象类型，是个枚举值，声明语句的 type 固定是 comment
}
```

##### 图解五类对象之间的继承关系

从上一段可以知道，<font color=LightSeaGreen>CSS 被解析成 Declaration、Rule、Root、AtRule、Comment 对象</font>。<font color=fuchsia>**这些对象有很多 公共方法，PostCSS 用了面向对象的继承思想，把公共方法和公共属性提取到了父类中**</font>。

<font color=fuchsia>**Root、Rule、AtRule** 都是可以有子节点的</font>，都有 nodes 属性，<font color=fuchsia>**他们三个继承自 Container 类**</font>，对 nodes 的操作方法都写在 Container 类中。

<font color=fuchsia>**Container、Declaration、Comment** **继承自 Node 类**</font>，所有对象都有 `Symbol('isClean')` 、`Symbol('my')`、raws、source、type 属性，都有 `toString()`、`error()` 等方法，这些属性和方法都定义在 Node 类中。

**Container、Node** 是用来提取公共属性和方法，不会生成他们的实例。

<font color=dodgerBlue>五个类之间的继承关系如下图所示：</font>

![Image](https://s2.loli.net/2022/08/12/c6po81SKtVYMnXv.png)

图中没有穷举类的方法，全部的方法 可以看直接看源码文件: https://github.com/postcss/postcss/tree/main/lib

#### 第二阶段：runPlugin

<font color=LightSeaGreen>PostCSS 本身并不处理任何具体的任务，只有当我们为其附加各种插件之后，它才具有实用性</font>。

<font color=fuchsia>PostCSS 在把 CSS string 解析成 AST 对象后，会扫描一边 AST 对象</font>，<font color=fuchsia>**每一种 AST 的对象都可以有对应的监听器**</font>。<font color=red>在遍历到某类型的对象时，如果有对象的监听器，就会执行其监听器</font>。

##### 第一类监听器

PostCSS 提供的**「以特定属性或者规则命名」**的事件监听器，如下：

> CHILDREN 代表子节点的事件监听器。

```js
// root
['Root', CHILDREN, 'RootExit']

// AtRule
['AtRule', 'AtRule-import', CHILDREN, 'AtRuleExit', 'AtRuleExit-import']

// Rule
['Rule', CHILDREN, 'RuleExit']

// Declaration
['Declaration', 'Declaration-color', 'DeclarationExit', 'DeclarationExit-color']

// Comment
['Comment', 'CommentExit']
```

PostCSS 以 <font color=fuchsia size=4>**深度优先** 的方式遍历 AST 树</font>。

- <mark style="background: lightpink">**遍历到 Root 根对象**，**第一步** 会执行所有插件注册的 Root 事件监听器，**第二步** 检查 Root 是否有子对象，如果有，则遍历子对象，执行子对象对应的事件监听器；如果没有子对象，则直接进入第三步；**第三步** 会执行所有插件注册的 RootExit 事件监听器</mark> （👀 注：这就是 DFS 的步骤）。

  <font color=red>插件注册的 Root、RootExit 事件的监听器 **只能是函数**</font>。函数的第一个参数是当前访问的 AST 的 Root 对象，第二个参数是 postcss 的 Result 对象和一些其他属性，通过 Result 对象可以获取 css string、opts 等信息。

  ```js
  {
    Root: (rootNode, helps) => {},
    RootExit: (rootNode, helps) => {}
  }
  ```

- **遍历到 Rule 对象**，则<mark style="background: lightpink">和访问 Root 根对象是一样的逻辑</mark>，先执行所有插件注册的 Rule 事件监听器，再遍历子对象，最后执行所有插件注册的 RuleExit 事件监听器。<font color=red>插件注册的 Rule、RuleExit 事件的监听器 **只能是函数**</font>。

  ```js
  {
    Rule: (ruleNode, helps) => {},
    RuleExit: (ruleNode, helps) => {}
  }
  ```

- **遍历到 AtRule 对象**。<font color=red>插件注册的 AtRule 的事件监听器 **可以是函数**，**也可以是对象**</font>。对象类型的监听器，对象属性的 key 是 AtRule 对象的 name 值，value 是函数。<mark style="background: lightpink">AtRuleExit 是一样的逻辑</mark>。<font color=fuchsia>事件的执行顺序是：`['AtRule', 'AtRule-import', CHILDREN, 'AtRuleExit', 'AtRuleExit-import']` </font>。CHILDREN 代表子节点的事件。

  ```js
   // 函数
  { 
    AtRule: (atRuleNode, helps) => {}
  }
  
  // 对象
  {
    AtRule: {
      import: (atRuleNode, helps) => {},
      keyframes: (atRuleNode, helps) => {}
    }
  }
  ```

- **遍历到 Declaration 对象**。<font color=red>插件注册的 Declaration 的事件监听器 **可以是函数，也可以是对象**</font>，对象属性的 key 是 Declaration 对象的 prop 值，value 是函数。<mark style="background: lightpink">DeclarationExitExit 是一样的逻辑</mark>。<font color=fuchsia>事件的执行顺序是：`['Declaration', 'Declaration-color', 'DeclarationExit', 'DeclarationExit-color']`</font> 。**Declaration 没有子对象，只需要执行当前对象的事件，不需要深度执行子对象的事件**。

  ```js
  // 函数
  {
    Declaration: (declarationNode, helps) => {}
  }
  
  // 对象
  {
    Declaration: {
      color: (declarationNode, helps) => {},
      border: (declarationNode, helps) => {}
    }
  }
  ```

- **遍历到 Comment 对象**。依次执行所有插件注册的 Comment 事件监听器，再执行所有插件注册的 CommentExit 事件监听器。

##### 第二类监听器

<font color=dodgerBlue>除以特定属性或者规则命名的事件监听器，**PostCSS 还有以下四个**</font>（👀 注：三个方法，一个插件名称）：

```js
{
  postcssPlugin: string,
  prepare: (result) => {},
  Once: (root, helps) => {},
  OnceExit: (root, helps) => {},
}
```

PostCSS 插件事件的整体执行是：`[prepare, Once, ...一类事件, OnceExit]`，<font color=red>**postcssPlugin 是插件名称**</font>，不是事件监听器。

- **postcssPlugin**：字符串类型，<font color=red>插件的名字，在插件执行报错，提示用户是哪个插件报错了</font>。

- **prepare**：函数类型，<font color=red>prepare 是最先执行的，在所有事件执行前执行的</font>，插件多个监听器间共享数据时使用。prepare 的入参是 Result 对象，返回值是监听器对象，通过 Result 对象可以获取 css string、opts 等信息。

  ```js
  {
    postcssPlugin: "PLUGIN NAME",
    prepare(result) {
      const variables = {};
      return {
        Declaration(node) {
          if (node.variable) {
            variables[node.prop] = node.value;
          }
        },
        OnceExit() {
          console.log(variables);
        },
      };
    },
  };
  ```

- **Once**：函数类型，<font color=red>在 prepare 后，一类事件前执行</font>，Once <font color=red>只会执行一次</font>。

  ```js
  {
     Once: (root, helps) => {}
  }
  ```

- **OnceExit**：函数类型，<font color=red>在一类事件后执行</font>，OnceExit <font color=red>只会执行一次</font>。

###### 插件有哪些？

[postcss Github - docs - PostCSS plugins](https://github.com/postcss/postcss/blob/main/docs/plugins.md) 列出了大量的 postcss plugin，就相当于 awesome postcss

> 💡 还有 [PostCSS.parts](https://www.postcss.parts/) 是一个 postcss 插件搜索工具
>
> > A searchable catalog of PostCSS plugins

> 💡 这里做一些 postcss 插件的介绍
>
> - [purgecss](https://github.com/FullHuman/purgecss) ：Remove unused CSS
>
> - [cssnano](https://github.com/cssnano/cssnano) ：A modular minifier, built on top of the PostCSS ecosystem. ( css 代码压缩工具)
>
> - [postcss-modules](https://github.com/madyankin/postcss-modules) : PostCSS plugin to use CSS Modules everywhere（给 css class 类名上加上 hash，使其具有不被同名 class 干扰）
>
> - [css-has-pseudo](https://github.com/csstools/postcss-plugins/tree/main/plugins/css-has-pseudo#readme) ：`:has()` 伪类的 postcss polyfill。下图是 `:has()` 的兼容性，可见：在 Chrome 105 和 Safari 15.4 才支持，兼容性很一般
>
>   <img src="https://s2.loli.net/2024/01/05/MF4fxCWVZ9vqr37.png" alt="image-20240105095547701" style="zoom:50%;" />

#### 第三阶段：generate

generate 的过程<font color=fuchsia>依旧是以深度优先的方式遍历 AST 对象，**针对不同的实例对象进行字符串的拼接**</font>。算法对应源码中位置是：`postcss/lib/stringifier.js` 中的 `stringify ` 方法，代码量不大，可自行查看。

摘自：[零基础理解 PostCSS 的主流程](https://mp.weixin.qq.com/s/Bkss0lzPT-TI6GyGxMyn3Q)



## Atomic CSS

> 👀 下面有 Tailwind CSS 和 Unocss 的笔记，虽然 Tailwind 使用场景和应用能力和 Unocss 几乎没什么区别；但根据习惯或者一般而言的生态，将在 React 下使用 Tailwind，Vue 下使用 UnoCSS



### 通用知识

##### 响应式断点 responsive breakpoints

###### 单位与含义

| Breakpoint        | Class infix | Dimensions |
| ----------------- | ----------- | ---------- |
| Extra small       | *None*      | <576px     |
| Small             | `sm`        | ≥576px     |
| Medium            | `md`        | ≥768px     |
| Large             | `lg`        | ≥992px     |
| Extra large       | `xl`        | ≥1200px    |
| Extra extra large | `xxl`       | ≥1400px    |

摘自：[BootStrap doc - layout - breakpoints # Available breakpoints](https://getbootstrap.com/docs/5.3/layout/breakpoints/#available-breakpoints)



### Taildwind CSS

##### 一些文章

- [你以为的 Tailwind 并不高效，看看这些使用误区](https://juejin.cn/post/7512652304745037865)



#### 环境配置

> 👀 由于 Next.js 自动集成了 Tailwind CSS 的各种配置，开箱即用，甚至提供了模版 [with-tailwindcss](https://github.com/vercel/next.js/tree/canary/examples/with-tailwindcss) ( 通过运行 `npx create-next-app --tailwind projName` 使用 )，不能进行从零到一的配置。所以，使用 Vite 了 react-ts 模版实现，其他的脚手架感觉也类似。

1. 运行 `pnpm create vite tailwind-vite-demo --template react-ts` 创建项目

2. 按照官方文档 [tailwindcss doc - Get started with Tailwind CSS # Using PostCSS](https://tailwindcss.com/docs/installation/using-postcss) 执行

   > ⚠️ 要看 “Using PostCSS” （或者 [Framework Guides](https://tailwindcss.com/docs/installation/framework-guides) 中的 [Vite](https://tailwindcss.com/docs/guides/vite) 部分），而不是默认的 “Tailwind CLI”

   1. 运行如下命令，安装 tailwindcss postcss autoprefixer，并初始化 tailwind

      ```sh
      npm install -D tailwindcss postcss autoprefixer
      npx tailwindcss init
      ```

   2. 添加 `postcss.config.js` 配置

      ```js
      export default {
        plugins: {
          tailwindcss: {},
          autoprefixer: {},
        }
      }
      ```

      > ⚠️ 如果这里是 Vite 的项目，最好使用 ES Module 的 `export default`，CJS 的 `module.export` 可能会警告。

   3. 添加 `tailwind.config.js` 配置

      ```js
      /** @type {import('tailwindcss').Config} */
      export default {
        content: [
          "./index.html",
          "./src/**/*.{js,ts,jsx,tsx}",
        ],
        theme: {
          extend: {},
        },
        plugins: [],
      }
      ```

   4. 添加 tailwind 指令 ( Tailwind directives ) 到全局 CSS 文件

      ```css
      // index.css
      @tailwind base;
      @tailwind components;
      @tailwind utilities;
      ```

   5. 配置完成，可以通过 `pnpm dev` 运行项目，并使用 tailwind 了



#### 一些概念

##### Design Token



##### tailwind-variants



### UnoCSS

#### 环境配置

1. 运行 `npm create vue@latest` 创建项目

2. 参考 [UnoCSS doc - integrations - Vite Plugin](https://unocss.dev/integrations/vite) 按照步骤操作

   1. 安装 UnoCSS

      ```sh
      pnpm add -D unocss
      ```

   2. 在 `vite.config.ts` 中配置 UnoCSS

      ```ts
      // vite.config.ts
      import UnoCSS from 'unocss/vite'
      import { defineConfig } from 'vite'
      
      export default defineConfig({
        plugins: [
          UnoCSS(),
        ],
      })
      ```

   3. 创建 `uno.config.ts` 并配置

      ```ts
      // uno.config.ts
      import { defineConfig } from 'unocss'
      
      export default defineConfig({
        // ...UnoCSS options
      })
      ```

   4. 将 `virtual:uno.css` 添加到主入口 ( main entry ) `main.ts` 中

      ```ts
      // main.ts
      import 'virtual:uno.css'
      ```

3. 其他配置

   ```ts
   // uno.config.ts
   import {
     defineConfig,
     presetUno,
     presetIcons,
     presetAttributify,
     presetTypography,
     presetWebFonts,
     presetTagify
   } from 'unocss'
   import presetRemToPx from '@unocss/preset-rem-to-px'
   
   export default defineConfig({
     presets: [
       presetUno(),
       presetRemToPx(),
       presetIcons(),
       presetAttributify(),
       presetTypography(),
       presetWebFonts(),
       presetTagify()
     ],
   })
   ```

   
## Vite

<font color=dodgerBlue>前端工程都有哪些痛点呢？</font>

首先是前端的 **模块化需求**。我们知道，业界的模块标准非常多，包括 ESM、CommonJS、AMD 和 CMD 等等。前端工程一方面需要落实这些模块规范，保证模块正常加载；<font color=lightSeaGreen>另一方面需要兼容不同的模块规范，以适应不同的执行环境</font>。

其次是**兼容浏览器，编译高级语法**。由于浏览器的实现规范所限，只要高级语言/语法（TypeScript、 JSX 等）想要在浏览器中正常运行，就必须被转化为浏览器可以理解的形式。这都需要工具链层面的支持，而且这个需求会一直存在。

再者是**线上代码的质量**问题。和开发阶段的考虑侧重点不同，生产环境中，我们<font color=red>不仅要考虑代码的 安全性、兼容性问题，保证线上代码的正常运行，也需要考虑代码运行时的性能问题</font>。由于浏览器的版本众多，代码兼容性和安全策略各不相同，线上代码的质量问题也将是前端工程中长期存在的一个痛点。

同时，开发效率也不容忽视。 我们知道，**项目的冷启动/二次启动时间**、**热更新时间** 都可能严重影响开发效率，尤其是当项目越来越庞大的时候。因此，提高项目的启动速度和热更新速度也是前端工程的重要需求。

那么，<font color=dodgerBlue>前端构建工具是如何解决以上问题的呢？</font>

<img src="https://s2.loli.net/2024/02/29/96DxvlrIFdHgkCO.webp" style="zoom:45%;" />

- 模块化方面，提供模块加载方案，并兼容不同的模块规范。
- 语法转译方面，<font color=lightSeaGreen>配合 `Sass`、`TSC`、`Babel` 等前端工具链，完成高级语法的转译功能</font>，同时对于静态资源也能进行处理，使之能作为一个模块正常加载。
- 产物质量方面，在生产环境中，配合 `Terser` 等压缩工具进行代码压缩和混淆，通过 `Tree Shaking` 删除未使用的代码，提供对于低版本浏览器的语法降级处理等等。
- 开发效率方面，构建工具本身通过各种方式来进行性能优化，包括 使用原生语言 Go/Rust、<font color=red>no-bundle</font> 等等思路，提高项目的启动性能和热更新的速度。

##### Vite 的优点

一方面，<font color=fuchsia>Vite 在开发阶段基于浏览器原生 ESM 的支持实现了 **`no-bundle`** 服务</font>，另一方面借助 esbuild 超快的编译速度来做第三方库构建和 TS / JSX 语法编译，从而能够有效提高开发效率。

<font color=dodgerBlue>除了开发效率，在其他三个维度上， Vite 也表现不俗</font>。

- 模块化方面，Vite 基于浏览器原生 ESM 的支持实现模块加载，<font color=red>并且无论是开发环境还是生产环境，都可以将其他格式的产物（如 CommonJS ）转换为 ESM</font> 。
- 语法转译方面，Vite 内置了对 TypeScript、JSX、Sass 等高级语法的支持，也能够加载各种各样的静态资源，如图片、Worker 等等。
- 产物质量方面，Vite 基于成熟的打包工具 Rollup 实现生产环境打包，同时可以配合 Terser、Babel 等工具链，可以极大程度保证构建产物的质量。



##### Vite 预构建

<font color=dodgerBlue>依赖预构建主要做了两件事情：</font>

- 一是将其他格式（如 UMD 和 CommonJS ）的产物转换为 ESM 格式，使其在浏览器通过 `<script type="module"><script>` 的方式正常加载。

- 二是打包第三方库的代码，将各个第三方库分散的文件合并到一起，减少 HTTP 请求数量，避免页面加载性能劣化。

Vite 将预构建相关的配置项都集中在 `optimizeDeps` 属性上



#### Vite 实现

##### Vite 架构图

![Vite 架构图](https://s2.loli.net/2024/03/04/Co6nIzVmHJBqUgR.webp)

##### esbuild 作为打包工具的缺点

- <font color=red>不支持降级到 `ES5` 的代码</font>。这意味着在低端浏览器代码会跑不起来。

- 不支持 `const enum` 等语法。这意味着单独使用这些语法在 esbuild 中会直接抛错。

  > 💡对于这里的说法感觉有点奇怪，所以问了下 GitHub Copilot：
  >
  > <img src="https://s2.loli.net/2024/03/04/ldfOVyAcg7e8XzY.png" alt="image-20240304141838375" style="zoom:50%;" />
  >
  > <img src="https://s2.loli.net/2024/03/04/cbjEtX9kMqnLFdm.png" alt="image-20240304142003366" style="zoom:50%;" />
  >
  > 根据上面的说法：esbuild 是支持 ts 的，只是不支持部分语法

- <font color=red>不提供操作打包产物的接口，像 Rollup 中灵活处理打包产物的能力</font>（如 `renderChunk` 钩子）在 esbuild 当中完全没有。

- <font color=red>不支持自定义 Code Splitting 策略</font>。传统的 Webpack 和 Rollup 都提供了自定义拆包策略的 API，而 esbuild 并未提供，从而降级了拆包优化的灵活性。



##### esbuild 为什么性能高

1. **使用 Golang 开发**，构建逻辑代码直接被编译为原生机器码，而不用像 JS 一样先代码解析为字节码，然后转换为机器码，大大节省了程序运行时间。
2. **多核并行**。内部打包算法充分利用多核 CPU 优势，所有的步骤尽可能并行，这也是得益于 Go 当中多线程共享内存的优势。
3. **从零造轮子**：<font color=red>几乎没有使用任何第三方库，所有逻辑自己编写</font>，大到 AST 解析，小到字符串的操作，保证极致的代码性能。
4. **高效的内存利用**。esbuild 中从头到尾尽可能地复用一份 AST 节点数据，而不用像 JS 打包工具中频繁地解析和传递 AST 数据（如 string -> TS -> JS -> string)，造成内存的大量浪费。



#### 拆包

##### 名词解释

- `bundle` 指的是整体的打包产物，包含 JS 和各种静态资源。
- `chunk` 指的是打包后的 JS 文件，是 `bundle` 的子集。
- <font color=red>`vendor` 是指第三方包的打包产物</font>，是一种特殊的 chunk。

##### Code Splitting 解决的问题

在传统的单 chunk 打包模式下，当项目代码越来越庞大，最后会导致浏览器下载一个巨大的文件，从页面加载性能的角度来说，主要会导致两个问题：

1. 无法做到 <font color=red>**按需加载**</font>，即使是当前页面不需要的代码也会进行加载。
2. 线上 <font color=fuchsia>**缓存复用率**极低</font>，<font color=red>改动一行代码即可导致整个 bundle 产物缓存失效</font>。

关于第一点：一般而言，<font color=dodgerBlue>**一个前端页面中的 JS 代码可以分为两个部分**</font>：<font color=red>**`Initital Chunk` 和 `Async Chunk`**</font> ，前者指页面首屏所需要的 JS 代码，而后者当前页面并不一定需要，一个典型的例子就是 路由组件，与当前路由无关的组件并不用加载。项目被打包成单 bundle 之后，无论是 `Initial Chunk` 还是 `Async Chunk` ，都会打包进同一个产物，也就是说，浏览器加载产物代码的时候，会将两者一起加载，导致许多冗余的加载过程，从而影响页面性能。<font color=red>通过`Code Splitting` 我们可以将按需加载的代码拆分出单独的 chunk，这样应用在首屏加载时只需要加载 `Initial Chunk` 即可</font>，避免了冗余的加载过程，使页面性能得到提升。

关于第二点：线上的 缓存命中率 ( 👀 cache hint ratio ) 是一个重要的性能衡量标准。对于线上站点而言，服务端一般在响应资源时加上一些 HTTP 响应头，最常见的响应头之一就是 `cache-control` ，它可以指定浏览器的**强缓存**，比如设置为下面这样：

```http
cache-control: max-age=31536000
```

表示资源过期时间为一年，在过期之前，访问**相同的资源 url**，浏览器直接利用本地的缓存，并不用给服务端发请求，这就大大降低了页面加载的网络开销。不过，在单 chunk 打包模式下面，一旦有一行代码变动，整个 chunk 的 url 地址都会变化。

##### Vite 默认拆包策略

在生产环境下 Vite 完全利用 Rollup 进行构建，因此拆包也是基于 Rollup 来完成的，但 Rollup 本身是一个专注 JS 库打包的工具，对应用构建的能力还尚为欠缺，Vite 正好是补足了 Rollup 应用构建的能力，在拆包能力这一块的扩展就是很好的体现。



#### 语法降级与 Polyfill

<font color=dodgerBlue>旧版浏览器的语法兼容问题主要分两类：**语法降级问题** 和 **Polyfill 缺失问题**</font>。前者比较好理解，比如某些浏览器不支持箭头函数，我们就需要将其转换为 `function() {}` 语法；而对后者来说，`Polyfill` 本身可以翻译为 “垫片”，也就是为浏览器提前注入一些 API 的实现代码，如 `Object.entries` 方法的实现，这样可以保证产物可以正常使用这些 API，防止报错。

<font color=fuchsia>这两类问题本质上是通过前端的 **编译工具链（如 `Babel` ）** 及 **JS 的基础 Polyfill 库（如 `core-js` ）**来解决的</font>，不会跟具体的构建工具所绑定。也就是说，对于这些本质的解决方案，在其它的构建工具（如 Webpack ）能使用，在 Vite 当中也完全可以使用。

##### 底层工具链

解决上述提到的两类语法兼容问题，<font color=dodgerBlue>主要需要用到两方面的工具</font>，分别包括：

- **编译时工具**。代表工具有 `@babel/preset-env` 和 `@babel/plugin-transform-runtime` 。
- **运行时基础库**。代表库包括 `core-js` 和 `regenerator-runtime` 。

**编译时工具**的作用是在代码编译阶段进行**语法降级**及**添加 `polyfill` 代码的引用语句**，如：

```ts
import "core-js/modules/es6.set.js"
```

由于这些工具只是编译阶段用到，运行时并不需要，需要将其放入 `package.json` 中的 `devDependencies` 中。

**运行时基础库**是根据 ECMAScript 官方语言规范提供各种 Polyfill 实现代码，主要包括 `core-js` 和 `regenerator-runtime` 两个基础库，不过在 babel 中也会有一些上层的封装，包括：

- [`@babel/polyfill`](https://link.juejin.cn/?target=https%3A%2F%2Fbabeljs.io%2Fdocs%2Fen%2Fbabel-polyfill)
- [`@babel/runtime`](https://link.juejin.cn/?target=https%3A%2F%2Fbabeljs.io%2Fdocs%2Fen%2Fbabel-runtime)
- [`@babel/runtime-corejs2`](https://link.juejin.cn/?target=https%3A%2F%2Fbabeljs.io%2Fdocs%2Fen%2Fbabel-runtime-corejs2)
- [`@babel/runtime-corejs3`](https://link.juejin.cn/?target=https%3A%2F%2Fbabeljs.io%2Fdocs%2Fen%2Fbabel-runtime-corejs3) 

<font color=lightSeaGreen>看似各种运行时库眼花缭乱</font>，<font color=red>其实 **都是 `core-js` 和 `regenerator-runtime` 不同版本的封装** 罢了</font>（ <font color=red>`@babel/runtime` 是个特例，不包含 `core-js` 的 Polyfill</font> ）。这类库是项目运行时必须要使用到的，因此一定要放到 `package.json` 中的 `dependencies` 中。

##### 实际使用

安装一些必要的依赖：

```bash
pnpm i @babel/cli @babel/core @babel/preset-env
```

<font color=dodgerBlue>各个依赖的作用：</font>

- `@babel/cli` ：为 babel 官方的脚手架工具，很适合我们练习用。
- `@babel/core` ：babel 核心编译库。
- `@babel/preset-env` ：babel 的预设工具集，基本为 babel 必装的库。

在测试项目中编写示例代码：

```js
const func = async () => {
  console.log(12123)
}

Promise.resolve().finally();
```

可以看到，示例代码中既包含了“高级语法”也包含现代浏览器的 API ，正好可以针对语法降级和 Polyfill 注入两个功能进行测试。

新建 `babelrc.json` 即 babel 的配置文件，内容如下:

```json
{
  "presets": [
    [
      "@babel/preset-env", 
      {
        // 指定兼容的浏览器版本
        "targets": {
          "ie": "11"
        },
        // 基础库 core-js 的版本，一般指定为最新的大版本
        "corejs": 3,
        // Polyfill 注入策略，后文详细介绍
        "useBuiltIns": "usage",
        // 不将 ES 模块语法转换为其他模块语法
        "modules": false
      }
    ]
  ]
}
```

其中有两个比较关键的配置：`targets` 和 `usage`

我们可以通过 `targets` 参数指定要兼容的浏览器版本，你既可以填如上配置所示的一个对象：

```json
{
  "targets": {
    "ie": "11"
  }
}
```

也可以用 Browserslist 配置语法：

```js
{ 
  // ie 不低于 11 版本，全球超过 0.5% 使用，且还在维护更新的浏览器
  "targets": "ie >= 11, > 0.5%, not dead"
}
```

<font color=lightSeaGreen>Browserslist 是一个帮助我们设置目标浏览器的工具</font>，<font color=fuchsia>不光是 Babel 用到，其他的编译工具如 `postcss-preset-env`、`autoprefix` 中都有所应用</font>。对于 `Browserslist` 的配置内容，既可以放到 Babel 这种特定工具当中，也<font color=dodgerBlue>可以在 `package.json` 中通过 `browserslist` 声明</font>：

```json
// package.json
{ 
  "browserslist": "ie >= 11"
}
```

<font color=dodgerBlue>或者通过 `.browserslistrc` 进行声明</font>：

```js
// .browserslistrc
ie >= 11
```

在实际的项目中，<font color=red>一般我们可以将使用下面这些**最佳实践集合**来描述不同的浏览器类型，减轻配置负担</font>：

```js
// 现代浏览器
last 2 versions and since 2018 and > 0.5%
// 兼容低版本 PC 浏览器
IE >= 11, > 0.5%, not dead
// 兼容低版本移动端浏览器
iOS >= 9, Android >= 4.4, last 2 versions, > 0.2%, not dead
```

对于这些配置对应的具体浏览器列表，可以去 [browserslist.dev](https://link.juejin.cn/?target=https%3A%2F%2Fbrowserslist.dev) 站点查看：

![image-20240309213234281](https://s2.loli.net/2024/03/09/MvEKRYOmpWCqAtj.png)

另外一个重要的配置 `useBuiltIns`，它决定了添加 Polyfill 策略，<font color=lightSeaGreen>默认是 `false`</font> ，即<font color=lightSeaGreen>不添加任何的 Polyfill</font> ；也可以手动将 `useBuiltIns` 配置为 `entry` 或者 `usage`

###### `useBuiltIns: entry`

> 💡 `entry` 表示手动引入（相较于 `usage` 的按需引入）
>
> 学习自：[小满zs - react最新教程 - React工具篇(babel)](https://www.bilibili.com/video/BV1mcpPeMETt&p=4)

`entry` 配置规定你必须在入口文件（👀 一般是 `index.js` ）手动添加一行这样的代码：

```js
import 'core-js';
```

在终端执行下面的命令进行 Babel 编译:

```bash
npx babel src --out-dir dist
```

产物输出在 `dist` 目录中，观察一下产物的代码：

![](https://s2.loli.net/2024/03/09/pZMBib4nqvPNF5L.webp)

<font color=red>Babel 已经**根据 “目标浏览器” 的配置**为我们添加了大量的 Polyfill 代码</font>，`index.js` 文件简单的几行代码被编译成近 300 行。实际上，Babel 所做的事情就是将 `import "core-js"` 代码替换成了产物中的这些具体模块的导入代码。

<font color=dodgerBlue>但这个配置有一个问题</font>，<font color=red>即无法做到按需导入</font>，上面的产物代码其实有大部分的 Polyfill 的代码我们并没有用到。这时候可以使用 `useBuiltIns: usage`

###### `useBuiltIns: usage`

试试 <font color=red>`useBuiltIns: usage` 按需导入配置</font>，改动配置后执行编译命令 `npx babel src --out-dir dist` ；同样可以看到产物输出在了 `dist/index.js` 中 ，内容如下所示：

![](https://s2.loli.net/2024/03/10/6kd9UFJM7fQXzZh.webp)

> 💡 <font color=red>Polyfill 代码 **主要来自 `core-js` 和 `regenerator-runtime`** ，因此如果要运行起来，必须要装这两个库</font>

可以发现 Polyfill 的代码精简了许多，真正地实现了按需 Polyfill 导入。因此，<font color=dodgerBlue>在实际的使用当中</font>，还是<font color=red>**推荐尽量使用 `useBuiltIns: "usage"`** ，进行按需的 Polyfill 注入</font>。

梳理一下，上面利用 `@babel/preset-env` 进行了目标浏览器语法的降级和 `Polyfill` 注入，同时用到了 `core-js` 和 `regenerator-runtime` 两个核心的运行时库。但 <font color=dodgerBlue>**`@babel/preset-env`  的方案也存在一定局限性**</font>：

1. 如果使用新特性，往往是通过基础库（如 `core-js` ）往全局环境添加 Polyfill，如果是开发应用没有任何问题，如果是开发第三方工具库，则很可能会对**全局空间造成污染**。

2. 很多工具函数的实现代码（如上面示例中的 `_defineProperty` 方法），会在许多文件中重现出现，造成**文件体积冗余**。

##### 更优的 Polyfill 注入方案：`transform-runtime`

> 💡需要提前说明的是，<font color=lightSeaGreen>`transform-runtime` 方案可以作为 `@babel/preset-env` 中 `useBuiltIns` 配置的替代品</font>，也就是说，<font color=dodgerBlue>**一旦使用 `transform-runtime` 方案**</font>，<font color=red>**应该把  `useBuiltIns` 属性设为 `false`**</font> 。

接下来尝试一下这个方案，<font color=dodgerBlue>首先安装必要的依赖</font>：

```sh
pnpm i @babel/plugin-transform-runtime -D
pnpm i @babel/runtime-corejs3 -S
```

<font color=dodgerBlue>解释一下这两个依赖的作用</font>：<font color=dodgerBlue>前者</font>是<font color=red>编译时</font>工具，用来转换语法和添加 Polyfill ；<font color=dodgerBlue>后者</font>是<font color=red>运行时</font>基础库，<font color=lightSeaGreen>封装了`core-js`、`regenerator-runtime` 和各种语法转换用到的 工具函数</font>。

> 💡 <font color=dodgerBlue>core-js 有三种产物</font>，<font color=red>分别是 **`core-js`、<font color=fuchsia>`core-js-pure`</font> 和 `core-js-bundle`**</font> 。第一种是全局 Polyfill 的做法，`@babel/preset-env` 就是用的这种产物；<font color=lightSeaGreen>第二种不会把 Polyfill 注入到全局环境，可以按需引入</font>；第三种是打包好的版本，包含所有的 Polyfill ，不太常用。`@babel/runtime-corejs3` 使用的是第二种产物。

对 `.babelrc.json` 作如下的配置：

```json
{
  "plugins": [
    // 添加 transform-runtime 插件
    [
      "@babel/plugin-transform-runtime", 
      {
        "corejs": 3
      }
    ]
  ],
  "presets": [
    [
      "@babel/preset-env",
      {
        "targets": {
          "ie": "11"
        },
        "corejs": 3,
        // 关闭 @babel/preset-env 默认的 Polyfill 注入
        "useBuiltIns": false,
        "modules": false
      }
    ]
  ]
}
```

执行终端命令 `npx babel src --out-dir dist` ，对比一下 `@babel/preset-env`下的产物结果：

![](https://s2.loli.net/2024/03/10/cnqXygZKLJO7Nxm.jpg)

经过对比不难发现，`transform-runtime` 一方面能够让我们在代码中使用 非全局版本 的 Polyfill，这样就避免全局空间的污染，这也得益于 `core-js` 的 pure 版本产物特性；另一方面<font color=dodgerBlue>对于 `asyncToGeneator` 这类的工具函数</font>，它也<font color=red>将其转换成了一段引入语句，不再将完整的实现放到文件中</font>，节省了编译后文件的体积。

另外，`transform-runtime` 方案引用的基础库也发生了变化，不再是直接引入 `core-js` 和 `regenerator-runtime`，而是引入 `@babel/runtime-corejs3` 。



#### Vite SSR 工程

SSR 中只能生成页面的内容和结构，并不能完成事件绑定，因此需要在浏览器中执行 CSR 的 JS 脚本，完成事件绑定，让页面拥有交互的能力，这个过程被称作 “hydrate”（译为 “注水” 或 “激活” )。同时，像这样服务端渲染 + 客户端 hydrate 的应用也被称为 “同构应用” 。

##### SSR 生命周期分析

SSR 会在服务端（主要是 Node.js 端）提前渲染出完整的 HTML 内容，<font color=dodgerBlue>这是如何做到的？</font>

<font color=dodgerBlue>**首先**</font>需要<font color=lightSeaGreen>保证前端的代码经过编译后放到服务端中能够正常执行</font>，<font color=dodgerBlue>**其次**</font><font color=lightSeaGreen>在服务端渲染前端组件，生成并组装应用的 HTML</font> 。这<font color=red>涉及到 SSR 应用的两大生命周期：“构建时” 和 “运行时”</font> ，不妨来仔细梳理一下。

<font color=dodgerBlue>先来看看 “构建时” 需要做哪些事情</font>：

1. **解决模块加载问题**。在原有的构建过程之外，需要加入 “SSR 构建” 的过程。具体来说，需要另外生成一份 CommonJS 格式的产物，使之能在 Node.js 正常加载。当然，随着 Node.js 本身对 ESM 的支持越来越成熟，也可以复用前端 ESM 格式的代码，Vite 在开发阶段进行 SSR 构建也是这样的思路。

   <img src="https://s2.loli.net/2024/03/16/sVnledjz8MWyOXN.png" style="zoom:50%;" />

2. **移除样式代码的引入**。直接引入一行 CSS 在服务端是无法执行的，因为 Node.js 并不能解析 CSS 的内容；但  CSS Modules 的情况除外，如下所示：

   ```ts
   import styles from './index.module.css'
   
   // 这里的 styles 是一个对象，如{ "container": "xxx" }，而不是 CSS 代码
   console.log(styles)
   ```

3. **依赖外部化 ( external )** ：对于某些第三方依赖并不需要使用构建后的版本，而是直接从 `node_modules` 中读取，比如 `react-dom`，这样在 SSR 构建的过程中将不会构建这些依赖，从而极大程度上加速 SSR 的构建。

   > 👀 关于上面的这句话有点不明白，问了下 GitHub Copilot Chat，得到如下回复：
   >
   > <img src="https://s2.loli.net/2024/03/16/y9K6wx2bstqvDhL.png" alt="Snipaste_2024-03-16_20-27-23" style="zoom:50%;" />

对于 SSR 的运行时，一般可以拆分为比较固定的生命周期阶段，<font color=dodgerBlue>简单来讲可以整理为以下几个核心的阶段</font>：

<img src="https://s2.loli.net/2024/03/16/qPDkQnXSN537Lxr.png" style="zoom:50%;" />

1. **加载 SSR 入口模块**。这个阶段，<font color=red>需要确定 SSR 构建产物的入口</font>，即组件的入口在哪里，并加载对应的模块。
2. **进行数据预取**。这时候 <font color=lightSeaGreen>Node 侧会通过查询数据库或者网络请求来获取应用所需的数据</font>。
3. **渲染组件**。<font color=red>这个阶段为 SSR 的核心</font>，<font color=lightSeaGreen>主要将第 1 步中加载的组件**渲染成 HTML 字符串或者 Stream 流**</font>。
4. **HTML 拼接**。在组件渲染完成之后，需要拼接完整的 HTML 字符串，并将其作为响应返回给浏览器。

<font color=dodgerBlue>从上面的分析中可以发现</font>，<font color=red>SSR 其实是 “构建” 和 “运行时” 互相配合才能实现的</font>，也就是说：仅靠构建工具是不够的，写一个 Vite 插件严格意义上无法实现 SSR 的能力，需要对 Vite 的构建流程做一些整体的调整，并且加入一些服务端运行时的逻辑才能实现。



#### 模块联邦

##### 模块共享之痛

对于一个互联网产品来说，一般会有不同的细分应用或子站；而<font color=lightSeaGreen>每个子站又彼此独立，可能由不同的开发团队进行单独的开发和维护</font>。<font color=dodgerBlue>看似没有什么问题，但实际上会经常遇到一些模块共享的问题</font>，也就是说：<font color=lightSeaGreen>**不同应用中总会有一些共享的代码，比如公共组件、公共工具函数、公共第三方依赖等等**</font>。<font color=dodgerBlue>对于这些共享的代码，除了通过简单的复制粘贴，还有没有更好的复用手段？</font>

###### 发布 npm 包

发布 npm 包是一种常见的复用模块的做法，可以将一些公用的代码封装为一个 npm 包，发布更新流程如下：

1. 公共库 lib1 改动，发布到 npm
2. 所有的应用安装新的依赖，并进行联调。

<img src="https://s2.loli.net/2024/03/17/oqtH7vkmrn3Mbzg.png" alt="image.png" style="zoom:45%;" />

封装 npm 包可以解决模块复用的问题，但它<font color=dodgerBlue>本身又引入了新的问题</font>：

1. **开发效率问题**。<font color=red>每次改动都需要发版，并所有相关的应用安装新依赖，流程比较复杂</font>。
2. **项目构建问题**。引入了公共库之后，公共库的代码都需要打包到项目最后的产物后，导致产物体积偏大，构建速度相对较慢。

因此，这种方案并不能作为最终方案，只是暂时用来解决问题的无奈之举。

###### Git Submodules

<font color=lightSeaGreen>通过 `git submodule` 可以将代码封装成一个公共的 Git 仓库</font>，然后<font color=red>**复用到不同的应用中**</font>；<font color=dodgerBlue>需要经历如下的步骤</font>：

1. 公共库 lib1 改动，提交到 Git 远程仓库
2. 所有的应用通过 `git submodule` 命令更新子仓库代码，并进行联调

你可以看到，<font color=red>**整体的流程其实跟发 npm 包相差无几**，仍然存在 npm 包方案所存在的各种问题</font>。

> 💡 补充
>
> <img src="https://s2.loli.net/2024/03/14/zJjUGqr7HvBNiQg.png" alt="image-20240314235428066" style="zoom:48%;" />

###### 依赖外部化 ( external ) + CDN 引入

某些第三方依赖并不需要让其参与构建，而是使用某一份公用的代码。按照这个思路，<font color=lightSeaGreen>可以在构建引擎中对某些依赖声明 `external`</font> ，然后在 HTML 中加入依赖的 CDN 地址：

```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/src/favicon.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vite App</title>
  </head>
  <body>
    <div id="root"></div>
    <!-- 从 CDN 上引入第三方依赖的代码 -->
    <script src="https://cdn.jsdelivr.net/npm/react@17.0.2/index.min.js"><script>
    <script src="https://cdn.jsdelivr.net/npm/react-dom@17.0.2/index.min.js"><script>
  </body>
</html>
```

如上面的例子所示，<font color=lightSeaGreen>可以对 `react` 和 `react-dom` 使用 CDN 的方式引入，**一般使用 `UMD` 格式产物**</font>，这样<font color=red>不同的项目间就可以通过 `window.React` 来使用同一份依赖的代码了，从而达到模块复用的效果</font>。不过在实际的使用场景，<font color=dodgerBlue>**这种方案的局限性也很突出**</font>：

1. <font color=red>**兼容性问题**</font>。并不是所有的依赖都有 UMD 格式的产物，因此这种方案不能覆盖所有的第三方 npm 包。

2. <font color=red>**依赖顺序问题**</font>。我们通常需要考虑间接依赖的问题，如对于 antd 组件库，它本身也依赖了 react 和 moment，那么 `react` 和 `moment` 也需要 `external` ，并且<font color=red>在 HTML 中引用这些包，同时也要 **严格保证引用的顺序**</font>，比如说 `moment` 如果放在了 `antd` 后面，代码可能无法运行。而第三方包背后的间接依赖数量一般很庞大，如果逐个处理，对于开发者来说简直就是噩梦。

   > 👀 顺带一提，当前 antd 已经不再使用 moment，而是 dayjs；至少项目 `package.json` 中找不到 moment，可以找到 dayjs

3. <font color=red>**产物体积问题**</font>。由于依赖包被声明 `external` 之后， <font color=fuchsia>应用在引用其 CDN 地址时，**会全量引用依赖的代码**，这种情况下就**没有办法通过 Tree Shaking 来去除无用代码**</font>，会导致应用的性能有所下降。

###### Monorepo

作为一种新的项目管理方式，Monorepo 也可以很好地解决模块复用的问题。在 Monorepo 架构下，多个项目可以放在同一个 Git 仓库中，各个互相依赖的子项目通过软链接的方式进行调试，<font color=lightSeaGreen>代码复用显得非常方便</font>，<font color=lightSeaGreen>如果有依赖的代码变动，那么用到这个依赖的项目当中**会立马感知到**</font>。

![](https://s2.loli.net/2024/03/15/swOJ6zEQlY3TBCg.png)

不得不承认，<font color=lightSeaGreen>**对于应用间模块复用的问题，Monorepo 是一种非常优秀的解决方案**</font>；但与此同时，<font color=dodgerBlue>它也给团队带来了一些挑战</font>：

1. **所有的应用代码必须放到同一个仓库**：<font color=lightSeaGreen>**如果是旧有项目，并且每个应用使用一个 Git 仓库的情况**</font>，那么<font color=red>使用 Monorepo 之后项目架构调整会比较大</font>，也就是说改造成本会相对比较高。
2. <font color=dodgerBlue>Monorepo 本身也存在一些天然的局限性</font>，如项目数量多起来之后依赖安装时间会很久、项目整体构建时间会变长等等，我们也需要去解决这些局限性所带来的的开发效率问题。而这项工作一般需要投入专业的人去解决，<font color=lightSeaGreen>如果没有足够的人员投入或者 **基建的保证**，Monorepo 可能并不是一个很好的选择</font>。
3. **项目构建问题**：跟发 npm 包的方案一样，所有公共代码都需要进入项目的构建流程中，产物体积还是偏大。

##### 模块联邦 核心概念

<font color=dodgerBlue>模块联邦中主要有两种模块</font>：<font color=red>“本地模块” 和 “远程模块”</font> 。

<font color=lightSeaGreen>**本地模块即为普通模块，是当前构建流程中的一部分**</font>；而<font color=red>远程模块不属于当前构建流程</font>，<font color=fuchsia>在本地模块的运行时进行导入，同时本地模块和远程模块可以共享某些依赖的代码</font>，如下图所示：

<img src="https://s2.loli.net/2024/03/17/2niUrJQap6PZztk.png" style="zoom:50%;" />

<font color=dodgerBlue>值得强调的是：在模块联邦中</font>，<font color=red>每个模块既可以是“本地模块”，导入其它的 “远程模块”，又可以作为“远程模块”，被其他的模块导入</font>。如下面这个例子所示:

<img src="https://s2.loli.net/2024/03/17/7d4jIXNBFA98fnv.png" style="zoom:55%;" />

如图，<font color=lightSeaGreen>其中 A 模块既可以作为本地模块导入 B，又可以作为远程模块被 C 导入</font>。

> 👀 既可以作为 consumer ，也可以作为 producer

以上就是模块联邦的主要设计原理，<font color=dodgerBlue>分析一下这种设计究竟有哪些优势</font>：

1. <font color=fuchsia>**实现任意粒度的模块共享**</font>。这里所指的<font color=red>模块粒度可大可小，包括第三方 npm 依赖、业务组件、工具函数，甚至可以是整个前端应用</font>！而整个前端应用能够共享产物，代表着各个应用单独开发、测试、部署，这也是一种微前端的实现。

   > 💡 这里的“任意粒度” 不经让人想到后端的消息队列的传输内容，问了下 GPT，得到肯定的回复：
   >
   > <img src="https://s2.loli.net/2024/09/02/1HUawvs5Jdt6ElZ.png" alt="image-20240902013822860" style="zoom:50%;" />

2. **优化构建产物体积**。<font color=red>远程模块可以从 **本地模块运行时** 被拉取，而 **不用参与本地模块的构建**，可以加速构建过程，同时也能减小构建产物</font>。

   > 💡 补充：
   >
   > Webpack Module Federation (MF) is a feature of webpack that allows for the dynamic loading of multiple versions of a module from multiple independent build systems.
   >
   > This allows for the creation of microfrontend-style applications, where <font color=red>multiple systems can share code and be dynamically updated **without having to rebuild the entire application**</font>.
   >
   > It also enables distributed teams and applications with different release cycles to share code without needing to wait for all systems to agree to and deploy a single shared version of a module.
   >
   > 摘自：[GitHub - Module Federation org](https://github.com/module-federation)

3. <font color=red>**运行时按需加载**</font>。<font color=lightSeaGreen>**远程模块导入的粒度可以很小**</font>，如果你只想使用 app1 模块的 `add` 函数，只需要在 app1 的构建配置中导出这个函数，然后<font color=lightSeaGreen>在本地模块中按照诸如 `import('app1/add')` 的方式导入即可</font>，这样就很好地实现了模块按需加载。

4. **第三方依赖共享**。<font color=lightSeaGreen>通过模块联邦中的共享依赖机制，可以很方便地实现在模块间公用依赖代码</font>，从而避免以往的 “external + CDN 引入” 方案的各种问题。

从以上的分析你可以看到，模块联邦近乎完美地解决了以往模块共享的问题，甚至能够实现应用级别的共享，进而达到微前端的效果。

> 💡 补充
>
> ![Snipaste_2024-03-17_21-44-33](https://s2.loli.net/2024/03/17/vbtwzNl8ILyV7qi.png)

##### 模块联邦 实现原理

<font color=dodgerBlue>实现模块联邦有三大主要的要素：</font>

1. `Host` 模块：即本地模块，用来消费远程模块。
2. `Remote` 模块：即远程模块，用来生产一些模块，并<font color=red>暴露 “运行时容器” 供本地模块消费</font>。
3. `Shared` 依赖：即<font color=red>共享依赖，用来在本地模块和远程模块中实现第三方依赖的共享</font>。



#### 再谈 ESM：高阶特性 & Pure ESM 时代

##### 高阶特性

###### import map

在浏览器中可以使用包含 `type="module"` 属性的 `script` 标签来加载 ES 模块，而<font color=dodgerBlue>模块路径主要包含三种</font>：

- 绝对路径，如  `https://cdn.skypack.dev/react`
- 相对路径，如 `./module-a`
- bare import ：即直接写一个第三方包名，如 `react`、`lodash`

<font color=red>前两种模块路径浏览器是原生支持的</font>，而<font color=dodgerBlue>对于 `bare import`</font>，<font color=red>在 Node.js 能直接执行</font>，<font color=red>因为 Node.js 的路径解析算法会从项目的 `node_modules` 找到第三方包的模块路径</font>，但是<font color=red>**放在浏览器中无法直接执行**</font>。而这种写法在日常开发的过程又极为常见，<font color=dodgerBlue>除了将 bare import 手动替换为一个绝对路径，还有其它的解决方案吗？</font>

答案是有的。现代浏览器内置的 `import map` 就是为了解决上述问题，<font color=dodgerBlue>可以用一个简单的例子来使用这个特性：</font>

```html
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Document</title>
</head>

<body>
  <div id="root"></div>
  <script type="importmap">
  {
    "imports": {
      "react": "https://cdn.skypack.dev/react"
    }
  }
  </script>

  <script type="module">
    import React from 'react';
    console.log(React)
  </script>
</body>

</html>
```

在浏览器中执行这个 HTML，如果正常执行，就可以看到浏览器已经从网络中获取了 react 的内容，如下图所示：

<img src="https://s2.loli.net/2024/03/13/IjqTWPVBfvtMdQs.png" alt="image-20240313235859282" style="zoom:50%;" />

> ⚠️ 注意
>
> <font color=red>`importmap` 可能存在浏览器兼容性问题</font>，所以<font color=red>如果浏览器中出现报错也属于正常情况</font>，下面会介绍解决方案

在支持 `import map` 的浏览器中，<font color=lightSeaGreen>在遇到 `type="importmap"` 的 `script` 标签时，浏览器会记录下第三方包的路径映射表</font>，<font color=red>在遇到 `bare import` 时会根据这张表拉取远程的依赖代码</font>。如上述例子中，使用 `skypack` 这个第三方的 ESM CDN 服务，通过 `https://cdn.skypack.dev/react` 这个地址可以拿到 React 的 ESM 格式产物。

> ⚠️ 注意
>
> 由于该教程是 Vite2 末期的小册，所以下面关于 `import map` 的兼容性和现在 (2024/3/14) 相比，已经有很大不同，从当时的 68.69% 到了现在的 91.2% ，兼容性好了不少；不过依然还是要考虑兼容性，尤其是 Safari 16.4 才支持 `import map`

`import map` 特性虽然简洁方便，但浏览器的兼容性却是个大问题，在 CanIUse 上的兼容性数据如下：

![image-20240314003351408](https://s2.loli.net/2024/03/14/IBaWg5jSOVLHAQo.png)

另外，`type="module"` 兼容了 95% 以上的浏览器

> 👀 现在 ( 2024/3/14 ) CanIUse 的百分比依然是 95.68%，没太大变化

社区已经有了对应的 Polyfill 解决方案：[es-module-shims](https://github.com/guybedford/es-module-shims)，<font color=dodgerBlue>完整地实现了包含 `import map` 在内的各大 ESM 特性，还包括：</font>

1. dynamic import ：即动态导入，部分老版本的 Firefox 和 Edge 不支持。

2. `import.meta` 和 `import.meta.url` 。当前模块的元信息，类似 Node.js 中的 `__dirname`、`__filename` 

3. `modulepreload` ：以前在 `link` 标签中加上 `rel="preload"` 来进行资源预加载，即在浏览器解析 HTML 之前就开始加载资源，现在对于 ESM 也有对应的 `modulepreload` 来支持这个行为。

4. `JSON Modules` 和 `CSS Modules`，即通过如下方式来引入 `json` 或者 `css` ：

   ```html
   <script type="module">
     // 获取 json 对象
     import json from 'https://site.com/data.json' assert { type: 'json' };
     // 获取 CSS Modules 对象
     import sheet from 'https://site.com/sheet.css' assert { type: 'css' };
   </script>
   ```

值得一提的是，<font color=lightSeaGreen>`es-module-shims` 基于 wasm 实现，性能并不差，相比浏览器原生的行为没有明显的性能下降</font>：

<img src="https://s2.loli.net/2024/03/14/ndGUI2R8DCaHFPK.png" style="zoom:45%;" />

##### Node.js 包导入导出策略

在 Node.js 中（ `>=12.20` 版本）一般有如下几种方式可以使用原生 ES Module ：

- 文件以 `.mjs` 结尾
- `package.json` 中声明 `type: "module"`。

那么，Node.js 在处理 ES Module 导入导出时，如果是处理 npm 包级别的情况，其中的细节比较复杂。

首先，<font color=dodgerBlue>如何导出一个包，有两种方式可以选择</font>： `main` 和 `exports` 属性。这两个属性均来自于 `package.json`，并且<font color=dodgerBlue>根据 Node 官方的 resolve 算法</font>（[查看详情](http://nodejs.cn/api/esm.html#resolver-algorithm-specification)），<font color=lightSeaGreen>**`exports` 的优先级比 `main` 更高**</font>，也就是说如果同时设置了这两个属性，`exports` 会优先生效。

`main` 的使用比较简单，设置包的入口文件路径即可，如：

```json
"main": "./dist/index.js"
```

###### `exports` 导入

需要重点梳理的是 <font color=dodgerBlue>**`exports` 属性，它包含了多种导出形式**</font>：“默认导出”、“子路径导出” 和 “条件导出”，这些导出形式如以下的代码所示：

```json
// package.json
{
  "name": "package-a",
  "type": "module",
  "exports": {
    // 默认导出，使用方式: import a from 'package-a'
    ".": "./dist/index.js",
    // 子路径导出，使用方式: import d from 'package-a/dist'
    "./dist": "./dist/index.js",
    "./dist/*": "./dist/*", // 这里可以使用 `*` 导出目录下所有的文件
    // 条件导出，区分 ESM 和 CommonJS 引入的情况
    "./main": {
      "import": "./main.js",
      "require": "./main.cjs"
    },
  }
}
```

其中，条件导出可以包括如下常见的属性：

- `node` ：在 Node.js 环境下适用，可以定义为嵌套条件导出，如：

  ```json
  {
    "exports": {
      {
        ".": {
         "node": {
           "import": "./main.js",
           "require": "./main.cjs"
          }     
        }
      }
    },
  }
  ```

- `import` ：用于 import 方式导入的情况，如 `import("package-a")`;

- `require` ：用于 require 方式导入的情况，如 `require("package-a")`;

- `default` ：兜底方案，如果前面的条件都没命中，则使用 default 导出的路径。

另外，条件导出还包含 `types`、`browser`、`develoment`、`production` 等属性，可以参考 Node.js 的 [详情文档](https://nodejs.org/api/packages.html#conditional-exports)，这里略。

###### `imports` 导出

再看 “导入”，也就是 `package.json` 中的 `imports` 字段，一般是这样声明的：

```json
{
  "imports": {
    // key 一般以 # 开头
    // 也可以直接赋值为一个字符串: "#dep": "lodash-es"
    "#dep": {
      "node": "lodash-es",
      "default": "./dep-polyfill.js"
    },
  },
  "dependencies": {
    "lodash-es": "^4.17.21"
  }
}
```

这样你可以在自己的包中使用下面的 import 语句：

```js
// index.js
import { cloneDeep } from "#dep";

const obj = { a: 1 };
console.log(cloneDeep(obj)); // { a: 1 }
```

Node.js 在执行的时候会将 `#dep` 定位到 `lodash-es` 这个第三方包，当然，也可以将其定位到某个内部文件。这样相当于实现了 “路径别名” 的功能，不过与构建工具中的 `alias` 功能不同的是，<font color=red>`imports` 中声明的别名必须全量匹配，否则 Node.js 会直接抛错</font>。



### Vite 实践补充

##### 带有查询后缀的导入

在看 Vite 文档时，对 [Vite doc - 功能 # 静态资源处理](https://cn.vitejs.dev/guide/features#static-assets) 以及更详细的 [Vite doc - 静态资源处理](https://cn.vitejs.dev/guide/assets) 中的 “[带有查询后缀的导入](https://cn.vitejs.dev/guide/features#import-with-query-suffixes)” 并没有放在心上，感觉和 webpack 中 resource query 类似的东西（虽然很大程度上，个人感觉是 Vite 文档写得相当浅）。

直到，看到 [读取文件原始内容【渡一教育】](https://www.bilibili.com/video/BV1WMWHenEVW) 发现通过对一个 base64 格式保存的图片文件，在引入时路径加上 `?raw` ，便可以替代 `webpack.config.js` 中定义 `module.rules.loader` 中配置 `raw-loader` 的效果，可以直接使用这个图片的导出结果



#### 构建相关

##### 分包控制

在 Vite 中可以使用 [`build.rollupOptions.output.manualChunks`](https://cn.rollupjs.org/configuration-options/#output-manualchunks) 来自定义 chunk 分割策略。另外，看了下文档，它的类型为 `{ [chunkAlias: string]: string[] } | ((id: string, {getModuleInfo, getModuleIds}) => string | void)` ，相较 webpack 中 [`optimization.splitChunks`](https://webpack.js.org/plugins/split-chunks-plugin) 的各种配置，要简单很多。

> 💡补充
>
> 25/06/28 发现 `manualChunks` 的用法还是不了解，建议看下 [[#通过 manualChunks 配置]]
>
> 另外，这里摘抄下 Rollup 这部分的文档：
>
> > 该选项允许你创建自定义的公共 chunk。<font color=dodgerBlue>当值为 **对象形式** 时</font>，<font color=red>**每个属性代表一个 chunk**</font>，<font color=red>**其中包含列出的模块及其所有依赖**</font>，除非他们已经在其他 chunk 中，否则将会是模块图 ( module graph ) 的一部分。<font color=red>**chunk 的名称由对象属性的键决定**</font>。
> >
> > > 👀 上面这句话有点难懂，在看完 [[#通过 manualChunks 配置]] 清晰了很多，就是：决定了某几个依赖放在同一个 chunk 中，而不是让构建工具自己决定；同时，这个 chunk 名称会包含对应的键名。
> >
> > 请注意，列出的模块本身不一定是模块图的一部分，该特性对于使用 `@rollup/plugin-node-resolve` 包并从中使用深度引用 ( deep imports ) 是非常有用的。例如：
> >
> > ```js
> > ({
> > 	manualChunks: {
> > 		lodash: ['lodash']
> > 	}
> > });
> > ```
> >
> > 上述例子中，即使你只是使用 `import get from 'lodash/get'` 形式引入，Rollup 也会将 lodash 的所有模块放到一个自定义 chunk 中。
> >
> > > 👀 下面还有 “`manualChunks` 值为函数形式” 的介绍，感觉短时间内，用不到，这里略。另外，上面的摘抄只需要看带高亮的第一段，即可。

###### Vite 构建产物的目录结构控制

在 rollup 中，可以通过 `output.entryFileNames` 设置构建产物的入口文件地址与文件名，通过 `output.chunkFileNames` 设置 chunk 的地址与文件名，通过 `output.assetFileNames` 设置所有静态文件（所有非 js 文件）的地址与文件名。上述三个属性为 `string | ((chunkInfo: ChunkInfo) => string)`，即：既可以是各种占位符 ( placeholder ) 以及字符形成的字符串 string，也可以是返回 string 的函数。

默认情况下，Vite 构建产物的目录结构如下；当然，这是工程简单的情况。

<img src="https://s2.loli.net/2024/05/11/5DpajkRzSi61MYb.png" alt="image-20240511001054437" style="zoom:50%;" />

可见 Vite 将图片、样式文件、js 等统统放入了 `assets/` 文件夹中，并没有给它们具体归类放入对应的文件夹。

如果想要实现归类，比如：把 js 文件放入 `js/` 文件夹，css 文件放入 `css/` 文件夹，图片文件放入 `imgs/` 文件夹，可以做在 `build.rollupOptions` 下做如下配置：

```ts
// vite.config.ts
export default defineConfig({
  // ...
  build: {
    rollupOptions: {
      output: {
        entryFileNames: 'js/[name]-[hash].js',
        chunkFileNames: 'js/[name]-[hash].js',
        // assetFileNames: '[ext]/[name]-[hash].[ext]'
        // 更进一步
        assetFileNames(assetInfo) {
          const { name } = assetInfo
          const lowerCaseName = name.toLowerCase()
          if (lowerCaseName.endsWith('.css')) {
            return 'css/[name]-[hash].css'
          }
          const imgExts = ['.png', '.jpg', '.jpeg', '.webp', '.svg', '.gif', '.ico']
          if (imgExts.some(ext => lowerCaseName.endWith(ext))) {
            return 'imgs/[name]-[hash].[ext]'
          }
          return 'assets/[name]-[hash].[ext]'
        }
      }
    }
  }
})
```

> 💡 补充
>
> 类似的，上述内容也可以在 webpack 中找到类似的配置，具体可见 [webpack doc - configuration - output](https://webpack.js.org/configuration/output)

学习自：[vite打包结构控制【渡一教育】](https://www.bilibili.com/video/BV1mH4y1G7BD)

###### 通过 manualChunks 配置

在阅读 [vite构建优化，速度提升了73% & rollup拆包8.4M降低至1000kb](https://juejin.cn/post/7446289008906616872) 发现了如下 `vite.config.ts` 配置：

```ts
rollupOptions: {
    output: {
      chunkFileNames: 'static/js/[name]-[hash].js',
      entryFileNames: 'static/js/[name]-[hash].js',
      assetFileNames: 'static/[ext]/[name]-[hash].[ext]',
      manualChunks: {
        vueChunk: ['vue', 'vue-router', 'pinia'],
        elementPlusChunk: ['element-plus','@element-plus/icons-vue'],
        customElementPlusChunk: ['@custom/icons-vue', '@custom/element-plus'],
        echartsChunk: ['echarts'],
        customChartsChunk: [ '@custom-charts/vue','@custom-charts/core'],
        utilsChunk: ['crypto-js','nprogress', 'axios', 'vue-i18n', 'dayjs'],
        statsChunk: ['@custom/stats-web']
      },
    }
}
```

有点没看懂，便问了下 Gemini ，得到了回复 https://g.co/gemini/share/3cb5cfc4bdd8 ，看了下，发现还是 `manualChunks` 的用法不了解，明明了类型约束已经写的很清楚了 `{ [chunkAlias: string]: string[] } | ((id: string, {getModuleInfo, getModuleIds}) => string | void)` ，这里显然是第一种 `{ [chunkAlias: string]: string[] }` 的用法，开发者设置 alias ，以及 alias 对应影响的依赖。

下面的内容摘自 Gemini 得回答：

> 结合您的 `output` 配置来看：
>
> ```ts
> output: {
>   chunkFileNames: 'static/js/[name]-[hash].js',
>   // ...
> }
> ```
>
> `chunkFileNames` 定义了非入口代码块的文件名格式。其中的 `[name]` 部分将会被 `manualChunks` 中你定义的 **键** 所替换。
>
> 所以，根据您的配置，最终打包生成的文件会是这样的：
>
> - `static/js/vueChunk-xxxxxxxx.js`: <font color=red>这个文件</font>将包含 `vue`, `vue-router`, 和 `pinia` 的代码。
> - `static/js/elementPlusChunk-xxxxxxxx.js`: 这个文件将包含 `element-plus` 和 `@element-plus/icons-vue` 的代码。
> - `static/js/echartsChunk-xxxxxxxx.js`: 这个文件将包含 `echarts` 的代码。
> - `static/js/utilsChunk-xxxxxxxx.js`: 这个文件将包含 `crypto-js`, `nprogress`, `axios` 等常用工具库的代码。
> - ... 以此类推。
>
> `xxxxxxxx` 部分是 Rollup 生成的 `[hash]`，用于缓存控制。

根据上面的表述相当于：决定了某几个依赖放在同一个 chunk 中，而不是让构建工具自己决定；同时，这个 chunk 名称会包含对应的键名。另外，这里的内容也可以看下 [[前端面试点总结#局部导入的优势]] 中的内容，感觉存在一定关联



##### Vite 构建移除项目中的 console

在 Vite 中内置了移除 console 设置的方法，在 `vite.config.js` 中配置即可。

```js
import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'

export default defineConfig({
  plugins: [vue()],
  build: {
    minify: 'terser',
    terserOptions: {
      compress: {
        //生产环境时移除console
        drop_console: true,
        drop_debugger: true,
      },
    },
  },
})
```

也可以使用 esbuild 自带的方法，相关文档见 [esbuild doc - api # drop](https://esbuild.github.io/api/#drop) ，`vite.config.js` 配置如下：

```js
import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'

export default defineConfig({
  plugins: [vue()],
  esbuild:{
    pure: ['console.log'],  
    drop: ['debugger'],
  },
})
```

也可以通过调库的方式：[GitHub - vite-plugin-remove-console](https://github.com/xiaoxian521/vite-plugin-remove-console) ，除了 console 看 readme 还支持 `custom` 以删除 `debugger` 之类

另外，在 Vue CLI 的项目中，只能使用 `babel-plugin-transform-remove-console` 插件。

学习自：[vite移除项目中的console](https://juejin.cn/post/6993225840117055496)



##### `tsconfig.node.json` 的作用

和 `tsconfig.json` 不一样，`tsconfig.node.json` 是用来管理 vite 的配置文件

学习自：[小满zs - react最新教程 - React基础篇(开发环境搭建)](https://www.bilibili.com/video/BV1mcpPeMETt&p=2)



## webpack

#### resource query

始终感觉对 resource query 概念有点不了解，不仅仅是刚开始在 webpack 中了解，在 Vite 中也有类似的写法（查看 Vite 中英文文档，但是对于 “resource query” 一点都搜不到）；再者，Google 搜索 “resource query” 前几条不是关于 AWS、Azure 等云服务的，就是 Resource Query Language 的，于是问了 GPT ：

<img src="https://s2.loli.net/2024/08/28/TK6OD1szb3hAeg9.png" alt="image-20240828101253028" style="zoom:50%;" />

<img src="https://s2.loli.net/2024/08/28/qFn7e8UXpT9k4hO.png" alt="image-20240828101331976" style="zoom:50%;" />

于是有点明白了。



## Vue

##### 判断项目是否使用 Vue 开发

> ⚠️ 以下方法均不适用于 Nuxt 开发的项目

可以使用 `window.__VUE__` 是否为真 ( true ) 来判断网站是否使用 Vue 开发

<img src="https://s2.loli.net/2024/09/28/rue8V4Y6DhBblKz.png" alt="image-20240928185610743" style="zoom:55%;" />

> 👀 文章中说：这是一定能对应上的，不过，存在 Nuxt 这个反例，确实不能说一定可以判断了。另外，看了下 `Object.getOwnPropertyDescriptor(window, '__VUE__')` 的结果，发现它是可写的，显然覆盖 `window.__VUE__` 也不是不可以
>
> <img src="https://s2.loli.net/2024/09/28/DbJztdWSKH5m984.png" alt="image-20240928190622674" style="zoom:55%;" />

如果是使用 Vue 开发，**一般情况下**可以使用 `window.app` 获取 Vue 实例，可以通过 `console.dir(window.app)` 查看。

<img src="https://s2.loli.net/2024/09/28/fZV42ldUmDe87gE.png" alt="image-20240928191817603" style="zoom:55%;" />

> 👀 之所以说是：一般情况，是因为这个 `app` 的属性名取决于模版 `index.html` 中绑定的根结点的 id 值。

其中，`window.app.__vue_app__` 中包含了当前网页用到的 Vue 版本（通过 `window.app.__vue_app__.version` 获取）和 Vue 上下文（通过  `window.app.__vue_app__._context` 获取）。

另外，`window.app._node` 可以获取 root 节点

学习自：[面试必备之如何判断一个网站是否是vue开发的？](https://juejin.cn/post/7243727090922815525)




## 杂项

#### unplugin-auto-import

##### 以 vite 为例的配置

```ts
// vite.config.ts
import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'
import AutoImport from 'unplugin-auto-import/vite' // 💡 除了 vite 还有 webpack 和 rollup 等等，详见文档

export default defineConfig({
  plugins: [vue(), AutoImport({
    imports: ['vue', 'vue-router'], // 需要导入哪些包中的模块
    dirs: ['./src/api'], // 需要导入的本地模块
    dts: './src/auto-import.d.ts', // 如果是 ts 开发，只有上面的配置，在开发时会发现类型声明丢失（如果是 js 不会存在这种问题！）；所以需要插件来自动生成类型定义，在启动项目之后，将会创建对应的文件，将 "imports" 和 "dirs" 中模块的类型定义写入其中。这里就是在说明生成类型定义文件的地址，可以按照自己想法定义。
  })]
})
```

按照如上配置，如下引入（以及类似的东西）将没有必要再写了

```ts
import { ref, reactive } from 'vue'
import { useRoute, useRouter } from 'vue-router'
import { foo } from './src/api'
```

另外，看了下官方 repo 的 readme [GitHub - unplugin-auto-import](https://github.com/unplugin/unplugin-auto-import) 感觉，相当易懂



#### changelog

可以使用 [conventional-changelog](https://github.com/conventional-changelog/conventional-changelog) 生成 changelog



#### Git hooks

通过 [`husky`](https://github.com/typicode/husky) 或 [`simple-git-hooks`](https://github.com/toplenboren/simple-git-hooks) 以使用 git hooks

其中，`husky` 的 star 数一骑绝尘（截止 2024/12/10 有 32.7k ），看得出来是最主流的方案。而 `simple-git-hooks` 是 Vue3 所使用的。

##### lint-staged

husky 会检查项目中所有的代码，中途接手一个老项目时会有很多错误。<font color=red>lint-staged 只检查本次提交所修改(指 git 暂存区里的东西)的问题，没修改过的不检查</font>

摘自：[前端组长如何在项目中统一代码格式](https://juejin.cn/post/7462554858513858595)

##### 各工具与作用

配套的工具推荐如下表所示：

| 工具             | 作用                                    |
| :--------------- | :-------------------------------------- |
| Commitlint       | 校验提交信息是否符合格式规范            |
| Husky            | Git 钩子管理工具（如提交前检查）        |
| lint-staged      | 提交前只格式化/检查改动的文件           |
| Standard Version | 自动生成 changelog、自动打 tag 和版本号 |

摘自：[为什么说 AI 时代，前端开发者对前端工程化的要求更高了？](https://mp.weixin.qq.com/s/NfdZAjNq4-brCDVjQw1NTg)

#### 项目依赖修改

[前端面试官：第三方npm包都不知道怎么修改吗？让你直接出门右拐](https://www.bilibili.com/video/BV1w9zCYPE76/) 中提及，当需要修改第三方 npm 包时，有三种方案，从上到下依次是更优的方案：

1. 将该 npm 包不通过 npm 管理，将其下载下来，直接存在项目中修改并使用
2. 使用 [`patch-package`](https://github.com/ds300/patch-package) 修改，并生成 patch 文件
3. fork 一份，修改并发布到 npm

##### 使用 patch-package

步骤如下：

1. 在 `package.json` 中添加如下 script ：

   ```diff
    "scripts": {
   +  "postinstall": "patch-package"
    }
   ```

2. 安装 [`patch-package`](https://github.com/ds300/patch-package) 

   ```sh
   npm i patch-package -D
   ```

3. 修改依赖。这里摘抄下文档中的示例

   ```sh
   # fix a bug in one of your dependencies
   vim node_modules/some-package/brokenFile.js
   ```

4. 运行 `patch-package` 命令

   ```sh
   # run patch-package to create a .patch file
   npx patch-package some-package
   ```

   到这步，在项目根目录下会生成一个 `patches` 文件夹，其中包含修改对比的 patch 文件，比如 `some-package+x.y.z.patch`

5. 提交代码

   ```sh
   # commit the patch file to share the fix with your team
   git add patches/some-package+3.14.15.patch
   git commit -m "fix brokenFile.js in some-package"
   ```




#### BFF

##### 介绍

BFF 主要用于为后端的微服务做中间层。可能存在这样的情况：后端微服务分的过细，服务器地址过多，导致前端接口对接异常麻烦，这时候需要一个中间层，将接口聚合在一起。

这个中间层需要前后端的一方来写，不过，按道理应该前段写。先说为什么后端不适合：因为后端是微服务，后端程序员未必能完全知道整个后端的全貌，所以一般而言让后端写不太好。接下来，为什么说前端适合：前端最清楚这些 API 的结构，也最清楚前端页面需要什么，所以前端适合；一般前端使用 Node 实现 BFF。

##### BFF 的作用

###### 充当适配器

改变 API 的外观

- 修改接口
- 聚合接口
- 数据脱敏（去除一些无需传给用户的信息）

###### 充当网管

- 缓存
- 安全
- 认证
- 黑白名单

学习自：[什么是BFF?它有什么用?【渡一教育】](https://www.bilibili.com/video/BV1V162YcEn2)



#### 字体优化

###### 对字体文件的引用方式

- 通过绝对路径来引用

  ```less
  @font-face {
    font-family: 'xxx';
    src: url('../../assets/fonts.woff2')
  }
  ```

- 引用 CDN 中存放的字体文件，一般是通过这种方式来减少工程的编译后体积

  ```less
  @font-face {
    font-family: 'xxx';
    src: url('https://cdn-url.woff2')
  }
  ```

- 通过 [FontFace API](https://developer.mozilla.org/zh-CN/docs/Web/API/FontFace) 构造一个字体对象，通过 js 控制字体的加载流程

##### 优化方向

| 方案       | 方法 / 原理                                                  | 适用场景                                                     |
| :--------- | :----------------------------------------------------------- | ------------------------------------------------------------ |
| 字体子集化 | 通过工具（比如 py 生态的 [fontTools](https://github.com/fonttools/fonttools)）<font color=red>将字体文件进行提取</font>（**支持动态**），<font color=red>返回指定的字符集的字体文件</font>，其根本就是**减少单次资源请求的体积**，需要服务端支持 | 这个方案是所有优化场景的基础                                 |
| 按需加载   | 通过设置 [`unicode-range`](https://developer.mozilla.org/en-US/docs/Web/CSS/@font-face/unicode-range) 属性，浏览器在进行 CSS 样式计算时候，会根据页面中的字符与设置的字符范围进行比对，匹配上会加载对应的字体文件 | <font color=red>前提是资源已经被子集化</font>，比较<font color=red>适用多语言切换的场景</font> |

简单来说，<font color=red>**字体子集化** 可单独食用</font>，<font color=red>**按需加载** 则必须 **要将字体前置子集化**</font>（👀 即：依赖 “字体子集化” ），才能完美实现按需加载。

如果目标字体使用的字符较少，可以只使用 “字体子集化”，即：通过动态的 “将服务本地中的字体资源子集化” 来实现字体的压缩效果。

<img src="https://s2.loli.net/2025/04/09/DIy5k91oqFuPWxs.jpg" style="zoom:50%;" />

> 👀 原文这里还有 Python Flask 调用 fontTools 的服务端代码，这里略，详见原文。另外，代码中省略了 import module 的代码，让 AI 补全了下，见 https://g.co/gemini/share/6d66a1c2cc69

> 💡在文章评论区发现了 [font-spider](https://github.com/aui/font-spider) 这个 字体压缩 ( Font subsetter ) 和文件格式转换工具 ( Font converter ) ，以及一个底层使用 [font-spider](https://github.com/aui/font-spider) 定向提取指定文字，并支持格式转换的在线工具 https://www.fontspider.vip

摘自：[因网速太慢我把20M+的字体压缩到了几KB](https://juejin.cn/post/7490337281866317836)




## 痛点与解决方案

#### 查看 dev server proxy 的真实地址

在使用 proxy 对开发服务器做代理时，可能会出现如下问题：

1. 配置 proxy 后，接口可能依然不通，需要查看配置，推算出真实的请求地址；甚至由于匹配规则是正则，推算会变得相当麻烦
2. 配置的 proxy 太多，记不住对应关系，总是需要再看下配置

这时候，如果每次请求的时候，都能够方便的看到 proxy 的对应关系就好了。

看到文章 [如何在浏览器控制台中看到webpack代理请求的真实url](https://juejin.cn/post/6865585028550787079) 中有提及 umi 在请求时会新增一个 `x-real-url` 的响应头，对应的值为真实请求的 url 地址（这样就可以在 DevTools 的 Network 选项中看到真实请求的地址了）；并且作者在文中给出了原理与实现方案：是利用 [`http-proxy-middleware`](https://github.com/chimurai/http-proxy-middleware) 中 `ProxyRes` 事件的 handler 实现的。实现代码如下：

```js
'targetUrlStrOrRegExp': {
  target: 'proxyServerUrl',
  changeOrigin: true,
  pathRewrite: { ... },
  onProxyRes: function (proxyRes, req, res) {
    const target = 'proxyServerUrl'
    const realUrl = target + req.url
    proxyRes.headers['x-real-url'] = realUrl
  }
}
```

`http-proxy-middleware` 适用于大多数以 webpack 作为构建工具的项目，其中也包含了 vue-cli 。不过，vite 的 proxy 继承自 [`http-proxy`](https://github.com/http-party/node-http-proxy#options) ，那便不能照搬上面的方法了。不过，感觉这些东西都是共通的，最多语法的设计不同；查了下，果然在 `http-proxy` 的 README 中找到了 `proxyRes` 事件。按照文档中的写法实现即可，如下：
```ts
'targetUrlStrOrRegExp': {
  target: 'proxyServerUrl',
  changeOrigin: true,
  pathRewrite: { ... },
  configure: (proxy, options) => {
    // proxy 是 'http-proxy' 的实例
    proxy.on('proxyRes', function (proxyRes, req, res) {
      const target = 'proxyServerUrl'
      const realUrl = target + req.url
      proxyRes.headers['x-real-url'] = realUrl
    }
  }
}
```